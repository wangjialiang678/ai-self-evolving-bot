# 进化系统配置
#
# LLM Provider 配置说明:
#   type: "anthropic" | "openai" (OpenAI 兼容接口)
#   model_id: 模型 ID
#   api_key_env: 环境变量名（从中读取 API key）
#   base_url: (可选) API 代理地址，不填则使用官方端点
#   extra_body: (可选) 额外请求参数
#
# 示例 — 通过代理访问 Claude:
#   opus:
#     type: anthropic
#     model_id: "claude-opus-4-6"
#     api_key_env: "PROXY_API_KEY"
#     base_url: "https://your-proxy.example.com"
#
llm:
  providers:
    opus:
      type: anthropic
      model_id: "claude-opus-4-6"
      api_key_env: "ANTHROPIC_API_KEY"
      # base_url: "https://your-proxy.example.com"  # 取消注释以使用代理
    qwen:
      type: openai
      model_id: "qwen/qwen3-235b-a22b"
      api_key_env: "NVIDIA_API_KEY"
      base_url: "https://integrate.api.nvidia.com/v1"
      extra_body:
        chat_template_kwargs:
          thinking: false
  aliases:
    gemini-flash: qwen

agent_loop:
  model: "opus"

observer:
  light_mode:
    enabled: true
    model: "qwen"
  deep_mode:
    schedule: "02:00"
    model: "opus"
    emergency_threshold: 3  # 24h 内 critical 信号数

architect:
  schedule: "03:00"
  model: "opus"
  max_daily_proposals: 3

approval:
  levels:
    0: {action: "auto_execute", notify: false}
    1: {action: "execute_then_notify", notify: true}
    2: {action: "propose_then_wait", notify: true}
    3: {action: "discuss", notify: true}

rollback:
  auto_threshold: 0.20
  backup_retention_days: 30

blast_radius:
  level_0_max_files: 1
  level_1_max_files: 3

rate_limit:
  max_daily_modifications: 5
  min_interval_hours: 2

communication:
  quiet_hours_start: "22:00"
  quiet_hours_end: "08:00"
  daily_report: true
  daily_report_time: "08:30"

evolution_strategy:
  initial: "cautious"
  transitions:
    cautious_to_balanced: {min_days: 7, min_success_rate: 0.70}
    balanced_to_growth: {stale_days: 14, min_success_rate: 0.80}
    any_to_repair: {success_drop: 0.20, critical_threshold: 3}
    repair_to_balanced: {recovery_days: 2}

cron:
  observer_cron: "0 2 * * *"
  architect_cron: "0 3 * * *"
  briefing_cron: "30 8 * * *"
  heartbeat_interval: 1800
