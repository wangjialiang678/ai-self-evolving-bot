# Self-Evolving Agent System: Research Topics

> **Date**: 2026-02-17  
> **Status**: 调研议题清单，每个议题需独立分析后才决定是否纳入系统  
> **Companion docs**: [Architecture v2.0](doc1_architecture_v2.md) | [Implementation Roadmap](doc2_roadmap_v2.md)

---

## 议题总览

| # | 议题 | 来源 | 优先级 | 预计影响 |
|---|------|------|--------|---------|
| R1 | 主动遗忘机制 | Reverse Inspiration #14 | 中 | 长期运行的系统健康度 |
| R2 | 两层智能正反馈循环的量化 | Reverse Inspiration #15 | 中 | 系统进化方向的监控 |
| R3 | 竞争性自评估机制 | Reverse Inspiration #16 | 高 | 进化决策的可靠性 |
| R4 | 代码→技能自动提炼的最佳实践 | EvoMaster 启发 #1 延伸 | 中 | CODER Agent 的核心能力 |
| R5 | 好奇心引擎 v2 的意图池设计 | Michael 反馈 #13 | 中 | V2 核心功能 |

---

## R1：主动遗忘机制

### 问题

系统运行一年后，MEMORY.md 可能膨胀到无法管理，daily/ 积累 365 个日志，skills/learned/ 塞满技能。信息过载会降低检索效率和质量。人类的遗忘是 Feature 不是 Bug——它帮助过滤不重要的信息。

### 需要调研的问题

1. **衰减函数选择**：语义记忆的权重应如何随时间衰减？
   - 线性衰减 vs 指数衰减 vs 幂律衰减
   - 衰减速率应该是固定的还是根据信息类型不同？
   - 参考认知科学中 Ebbinghaus 遗忘曲线是否合适？

2. **"被使用"如何定义**：
   - 被检索到（出现在搜索结果中）算"使用"吗？
   - 还是必须被实际注入上下文并影响了决策才算？
   - 被间接引用（通过它衍生出的规则被使用）算不算？

3. **遗忘的粒度**：
   - 语义记忆：按条目遗忘？按主题遗忘？
   - 情节记忆：30 天→摘要→90 天→月度总结→1年→年度总结？
   - 技能：多少次不使用后 deprecated？deprecated 后多久删除？

4. **遗忘的安全性**：
   - 遗忘机制会不会导致系统"忘掉"关键教训，重蹈覆辙？
   - 是否需要一个"永不遗忘"的标记机制？
   - 用户显式教授的知识应该免于自动遗忘吗？

5. **用户模型的刷新**：
   - 人会变，一年前的偏好可能过时
   - 如何检测偏好已过时？（最后使用时间 vs 与近期行为的一致性）
   - 是主动问用户"这还对吗？"还是静默降权？

### 调研方法建议

- 文献调研：认知科学中的遗忘理论 + 推荐系统中的时间衰减算法
- 模拟实验：生成一年的模拟交互数据，对比不同衰减策略下的检索质量
- 指标定义：定义"记忆健康度"指标（信号/噪声比 × 检索精度 × 覆盖率）

### 预期产出

一份包含推荐衰减策略、参数范围、和实现方案的技术文档。

---

## R2：两层智能正反馈循环的量化

### 问题

系统的核心目标是形成"LLM 基础推理 + 认知架构增强"的正反馈循环。但这个循环的具体机理和健康度缺乏量化定义。不知道循环在什么条件下加速、什么条件下停滞或退化。

### 需要调研的问题

1. **循环的量化定义**：

```
循环健康度 = f(
  记忆利用率,        // 被检索并实际影响决策的记忆比例
  反思转化率,        // 反思建议被采纳并验证有效的比例
  进化命中率,        // 突变中被保留的比例
  用户模型准确度,    // 预测 vs 实际的一致性
  提问效率           // 好奇心引擎提问后的质量提升
)
```

这个公式中各因子的权重如何确定？是否需要归一化？

2. **退化检测**：
   - 记忆质量下降（垃圾信息太多）怎么检测？
   - 进化方向错误（突变策略都很差）怎么检测？
   - 用户模型漂移（用户变了但模型没跟上）怎么检测？

3. **正反馈 vs 负反馈**：
   - 什么情况下循环是正反馈的（越来越好）？
   - 什么情况下会变成负反馈的（自我强化错误）？
   - 如何设计"刹车"机制防止负反馈失控？

4. **与 benchmark 的关系**：
   - 循环健康度指标能否预测系统在具体 benchmark 上的表现？
   - 是否存在"健康度高但实际表现不好"的情况？为什么？

### 调研方法建议

- 在 MVP 上跑 50+ 次任务后，收集所有相关数据
- 用相关性分析找出哪些因子和最终任务质量最相关
- 设计 A/B 实验：关闭某个循环环节，观察系统表现变化
- 参考控制论（cybernetics）中的反馈循环分析方法

### 预期产出

一个可实现的循环健康度监控方案，包含指标定义、计算方法、异常报警阈值。

---

## R3：竞争性自评估机制

### 问题

反思引擎"自己评价自己"存在偏差——LLM 倾向于对自己的输出给予更高评价。进化引擎的突变决策需要更可靠的评估方式。

### 需要调研的问题

1. **双策略对比的实现方式**：

```
方案 A：串行执行
  Task → 原策略执行 → Output A
  Task → 突变策略执行 → Output B
  独立 Critic → 对比评估
  
  优点：实现简单
  缺点：相同任务执行两次，成本翻倍

方案 B：影子执行
  Task → 原策略执行 → Output A（实际使用）
  同时后台用突变策略生成 Output B（不给用户看）
  积累够 N 次后统一对比
  
  优点：不影响用户体验
  缺点：后台成本高

方案 C：历史对比
  从历史数据中找到类似任务的 Output A
  用突变策略对当前任务生成 Output B
  对比评估
  
  优点：成本最低
  缺点：任务不完全相同可能影响对比公平性
```

哪种方案在成本和可靠性之间取得最佳平衡？

2. **独立 Critic 的设计**：
   - 应该用同一个模型还是不同模型做 Critic？
   - Critic 的评估标准是什么？（准确性？完整性？用户偏好匹配度？）
   - 如何避免 Critic 本身的偏差？
   - Critic 的评估结果本身是否需要校准？

3. **样本量和置信度**：
   - 需要多少次对比才能做出可靠的"保留/丢弃"决策？
   - 如何处理 A/B 测试中的噪声？
   - 改进阈值（improvement_threshold）应该设多少？

4. **成本控制**：
   - 双策略执行 + 独立评估的 token 成本是普通执行的 3-4 倍
   - 哪些突变值得做竞争性评估，哪些用简单的单路评估即可？
   - 是否可以先用低成本方法筛选，再对有希望的突变做高成本评估？

### 调研方法建议

- 实验：选 3 种不同方案各跑 20 次 A/B 测试，对比评估结果的一致性和成本
- 文献：参考 A/B 测试统计学方法，特别是小样本情况下的决策框架
- 参考 EvoMaster 的 Selector Agent 设计和评估策略

### 预期产出

一份推荐的竞争性评估方案，包含实现架构、成本估算、和样本量计算公式。

---

## R4：代码→技能自动提炼的最佳实践

### 问题

CODER Agent 会生成大量临时代码。其中一部分代码具有复用价值，应该被自动提炼为正式 Tool/Skill。但如何判断"哪些代码值得提炼"和"如何提炼"需要调研。

### 需要调研的问题

1. **复用识别**：
   - 什么算"复用"？完全相同的代码？语义相似的代码？解决同类问题的代码？
   - 复用阈值是多少？（3 次？5 次？）
   - 是基于代码文本相似度还是基于任务语义相似度？

2. **提炼方式**：
   - 从具体代码到通用工具需要什么抽象？
   - 参数化：哪些硬编码值应该变成参数？
   - 文档化：自动生成工具描述和使用示例？
   - 错误处理：原始代码可能没有完善的错误处理，提炼时是否应该补充？

3. **质量保证**：
   - 提炼出的工具如何验证正确性？
   - 是否需要自动生成测试用例？
   - 提炼后的工具和原始代码的行为是否一致？

4. **与现有技能的冲突**：
   - 如果提炼出的工具和已有工具功能重叠怎么办？
   - 合并？替换？共存？
   - 如何判断新工具是否"更好"？

### 调研方法建议

- 先让 CODER Agent 运行 50+ 次任务，收集所有生成的代码
- 人工分析哪些代码具有复用价值
- 尝试几种自动提炼策略，对比结果质量
- 参考软件工程中的代码重构和 API 设计最佳实践

### 预期产出

代码→技能自动提炼的流程设计和实现方案。

---

## R5：好奇心引擎 v2——意图池设计

### 问题

好奇心引擎从 v1（向用户提问）升级为 v2（AI 自主探索 + 意图池）。需要设计意图池的完整机制：如何生成意图、如何调度执行、如何呈现结果。

### 需要调研的问题

1. **意图生成**：
   - 什么情况下 AI 应该产生"我想了解 X"的意图？
   - 如何避免产生太多低价值的意图（"我想知道今天天气"）？
   - 意图的来源：任务执行中的缺口？用户兴趣领域的跟踪？系统能力的边界探索？
   - 意图的优先级如何确定？

2. **意图池管理**：
   - 意图池的容量限制？（100 个？1000 个？）
   - 意图的生命周期？（PENDING → IN_PROGRESS → RESOLVED / EXPIRED）
   - 过期策略：多久不处理的意图应该被清理？
   - 意图之间的依赖和冲突如何处理？

3. **与人类意图的融合**：
   - AI 的好奇心意图和用户的任务意图放在同一个池里
   - 调度优先级：用户任务 > 与当前任务相关的 AI 探索 > 后台 AI 探索
   - 如何避免 AI 探索占用过多资源影响用户任务？

4. **探索结果呈现**：
   - 每日摘要的最佳格式？长度？
   - 如何判断哪些探索结果值得呈现给用户？
   - 呈现的频率和时机？（每天固定时间？还是有了重要发现立即通知？）
   - 用户的反馈如何影响后续探索方向？

5. **与反思引擎的集成**：
   - AI 的探索结果是否应该触发反思？
   - 探索发现的新知识如何进入语义记忆？
   - 探索是否能产生新的技能？

### 调研方法建议

- 设计 3-5 种不同的意图池调度策略
- 用模拟用户交互数据测试每种策略的资源消耗和产出价值
- 参考推荐系统中的"探索-利用"平衡算法（如 Thompson Sampling）
- 参考 Voyager（Minecraft Agent）的好奇心驱动探索机制

### 预期产出

好奇心引擎 v2 的完整设计方案，包含意图池数据结构、调度算法、呈现策略。

---

## 调研执行建议

### 优先级排序

```
Phase 1（与 MVP 并行调研）:
  R3: 竞争性自评估 — 直接影响进化引擎的可靠性
  R4: 代码→技能提炼 — 直接影响 CODER Agent 的核心价值

Phase 2（V1.5 阶段调研）:
  R1: 遗忘机制 — 系统运行 1-2 个月后才会遇到信息膨胀
  R5: 好奇心 v2 — V2 阶段才实现，但可以先设计

Phase 3（V2 阶段调研）:
  R2: 正反馈循环量化 — 需要足够多的运行数据才能分析
```

### 每个议题的交付标准

每个调研议题完成后应产出：

1. **问题分析文档**：清晰定义问题、约束条件、评估标准
2. **方案对比**：至少 2 种可行方案的优劣对比
3. **推荐方案**：选择一种方案并说明理由
4. **实现规格**：足够详细的接口定义和数据结构
5. **验证计划**：如何验证方案的有效性

---

> 每个调研议题都可以交给 AI 做初步分析，但最终方案需要人类确认后才纳入系统设计。
