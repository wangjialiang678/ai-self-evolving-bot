# 自进化智能体系统：全文档审读笔记

> **日期**: 2026-02-22  
> **目的**: 对照 v3.1 设计，回溯所有历史文档，识别遗漏、启发与待澄清事项  
> **审读范围**: v1.0 三篇 → v2.0/v2.1 三篇 → v3.0/v3.1 两篇 + 对话纪要、Nanobot 分析、Claude 沙盒架构、多智能体协作报告、被动收入框架、多智能体辩论研究

---

## 一、从早期版本中可能遗漏或弱化的设计要素

以下条目在 v1.0/v2.1 中有详细设计或讨论，但在 v3.1 中被省略、简化或未显式继承。需要确认是"有意删减"还是"无意遗漏"。

### 1.1 CODER Agent 与"代码即交互语言"原则

**v2.1 中的设计**：CODER Agent 作为独立角色，可直接生成 Python 代码与环境交互。更重要的是，反思引擎会检测"某段代码被复用 ≥3 次"后，自动将其提炼为正式 Skill 注册到工具表——即"临时代码 → 验证有效 → 注册为工具"的自动进化路径。

**v3.1 状态**：MVP 不包含 CODER Agent，"代码即交互语言"这条设计原则（v2.1 原则 8）在 v3.1 的 15 条原则中未列入。NanoBot 本身有 ShellTool，但代码到技能的自动提炼路径完全缺失。

**建议确认**：
- 这是有意推迟到 Architect 后续提案？还是架构上需要预留接口？
- "代码→技能"自动提炼是否仍然是系统长期愿景的一部分？
- 在 NanoBot 基座上，ShellTool + 反思引擎是否可以初步实现这条路径？

### 1.2 难度路由器（Difficulty Router）

**v2.1 中的设计**：完整的三档路由（简单→单 Agent 串行 / 中等→PLANNER+2-3 Agent / 困难→Scattered-and-Stacked 并行→CRITIC 诊断→综合重新生成→选优）。路由器的阈值和分支策略本身也被设计为可进化参数。

**v3.1 状态**：MVP 明确"不包含难度路由"。但 Architect 后续提案中提到了"建议引入难度路由"的可能性。

**建议确认**：
- 当前 MVP 的单 Agent 模式下，如何处理明显需要多步骤协作的复杂任务？是退化到纯 LLM 能力，还是规则层有某种简化的任务分解机制？
- 难度路由的"可进化参数"概念是否应写入 Big Picture 作为远期目标？

### 1.3 好奇心引擎 v2：意图池（Intention Pool）

**v2.1 中的设计**：好奇心从"向人提问"重新定位为"AI 的认知内驱力"。引入了意图池统一管理 AI 自主产生的好奇心意图和用户的任务意图。意图有 `can_self_resolve` 标记，AI 可自主去调研解决。每日生成"探索摘要"主动通知用户。

**v3.1 状态**：好奇心引擎在 MVP 中完全缺失。Observer 有一些被动的信号检测，但缺乏主动探索机制。系统当前只有被动响应用户消息 + Observer/Architect 的反应式进化。

**建议确认**：
- v2.1 中意图池的核心理念——AI 主动对世界产生好奇、自主调研——是否仍然是系统长期目标的一部分？
- 这和 v3.1 中 Architect 的"主动触发"是否有交叉？Architect 可以被看作好奇心引擎的一个简化版本？
- NanoBot 的 Heartbeat 机制是否可以作为好奇心引擎的基础设施？

### 1.4 Human-as-Executor 模式

**v2.1 中的设计**：作为独立原则（原则 7）和独立组件设计。AI 可以规划、决策，并驱动人类去执行 AI 无法完成的部分（物理行动、人际沟通、受限资源访问等）。有完整的 `HumanExecutionRequest` 数据结构，包含 fallback、deadline、priority 等。

**v3.1 状态**：通过 Telegram 的"AI 主动发消息"有一定覆盖，但仅限于 Architect 的提案和报告推送。原始设计中"AI 分配具体任务给人、人作为执行节点"的完整模式未体现。

**建议确认**：
- Human-as-Executor 是否仍然是核心愿景的一部分？还是被 Architect 的"主动沟通"所替代？
- 从被动收入框架文档来看，Michael 非常重视"AI 做决策，人执行 AI 做不到的部分"——v3.1 应该如何体现这一点？
- 是否需要在 Architect 提案模板中预留"需要人类执行的具体行动"字段？

### 1.5 用户模型系统（四层模型 + 信念更新）

**v2.1 中的设计**：四层用户模型（表面偏好→工作模式→品味和判断→价值观和关切）。显式偏好即时生效 vs 推断偏好需通知确认的双通道机制。信念更新算法。用户模型以 YAML 存储，人可审查修改。

**v3.1 状态**：用户偏好被降维到 MEMORY.md 中的一个 section（`User Profile`），以及 `experience/user_preferences.md` 规则文件。四层模型的结构性和信念更新机制消失。

**建议确认**：
- 四层用户模型是否过度设计？还是 v3.1 的简化会导致对用户理解的深度不足？
- 显式偏好 vs 推断偏好的双通道机制，是否值得在 MVP 中就保留？这关系到系统"学习用户品味"的核心能力。
- `user_preferences.md` 规则文件和 `MEMORY.md` 中的 User Profile 之间的关系是什么？是否存在重复？

### 1.6 验证基准体系（Validation Benchmarks）

**v2.1 中的设计**：每个核心组件都有可测量的验证标准。memory_effectiveness、reflection_value、evolution_rate、compaction_quality、user_model_accuracy、context_engine_efficiency、difficulty_router_accuracy 都有明确的测试方法和目标阈值。

**v3.1 状态**：MVP 有 6 个成功衡量标准（闭环完整性、Observer 有效性、Architect 可用性、主动沟通、规则活性、回滚可靠性），但 v2.1 中组件级的量化验证体系未保留。

**建议确认**：
- v3.1 的 6 个标准更面向"MVP 是否可用"，而 v2.1 的标准更面向"每个组件是否有效"——后者是否应作为 Architect 后续评估修改效果的指标体系？
- 是否需要在 Big Picture 中保留组件级验证基准，供 Architect 在做改进提案时参考？

### 1.7 Compaction 的质量保障机制

**v2.0 中的设计**：7 步 Compaction 流程——包括关键信息锁定、认知层级转化（从简单摘要升级为事实提取+规律提炼+策略建议+用户信号）、压缩验证（用另一个 LLM 调用对比原始内容和摘要，检测高风险信息丢失）。

**v3.1 状态**：MVP 不包含"复杂的上下文压缩（Compaction）"。NanoBot 本身的记忆管理较简单。

**建议确认**：
- NanoBot 的 session 管理如何处理长对话？是否有内置的 Compaction？
- MVP 阶段如果对话超长，系统行为会如何退化？是否需要一个最简版的 Compaction？
- "认知层级转化"这个概念是否可以在反思引擎中部分实现？

### 1.8 Scattered-and-Stacked 推理扩展策略

**v2.0 中的设计**：来自 X-Master 启发。面对困难任务时，3-5 个 Agent 并行生成方案→CRITIC 诊断每个方案缺陷→综合所有方案重新生成改进版→CRITIC 从中选出最优解。

**v3.1 状态**：不在 MVP 范围内，但多智能体辩论研究（project knowledge 中有详细报告）表明这类机制在特定场景下有显著价值。

**建议确认**：
- 这是否应该出现在 Architect 的进化路线图中作为远期目标？
- 多智能体辩论研究的结论（如 DOWN 框架的自适应激活、异质团队比同质团队好 6 倍等）是否应纳入 Big Picture？

### 1.9 五维反思模板

**v1.0/v2.0 中的设计**：反思引擎使用五维反思 Prompt（具体维度在 doc2 中有详细定义）。每个维度产生不同类型的策略建议。

**v3.1 状态**：反思模板作为 `experience/reflection_templates.md` 存在于规则文件中，但具体的五维设计未在 v3.1 文档中展开。这意味着初始规则文件的内容质量将直接影响系统启动效果。

**建议确认**：
- 初始的 reflection_templates.md 应该包含什么内容？是否需要在 MVP 实施前就写好？
- v1.0 的五维反思设计（执行质量、策略有效性、信息充分性、用户满意度、改进空间）是否直接继承？

### 1.10 种子记忆与冷启动策略

**v2.1 中的设计**：明确的冷启动策略——种子记忆（通用常识规则 + 领域基础知识）、种子技能（5-10 个预置 Skill）、保守期策略（前 20 次任务不做基因突变、更频繁反思、频繁向用户了解偏好）。

**v3.1 状态**：有进化策略的 `cautious` 模式，但种子记忆和种子技能的概念未提及。初始规则集（~10 个文件）起到了部分种子作用，但缺少"对用户领域预判"的种子知识。

**建议确认**：
- 初始 MEMORY.md 应该包含什么种子内容？是否需要针对 Michael 的 SuperBrain AI 教育背景预置一些知识？
- 初始规则文件中是否需要包含"这是一个新系统，请在前 N 次交互中更积极地学习用户偏好"的元指令？

---

## 二、参考文档的启发与未充分利用的设计灵感

### 2.1 来自 Manus 的未充分利用启发

| 启发点 | Manus 原始设计 | v3.1 应用情况 | 建议 |
|--------|--------------|-------------|------|
| KV-Cache 优化 | 系统 prompt append-only，最大化缓存命中 | 未提及 | 规则注入到 system prompt 时，是否需要考虑 KV-cache 命中率？固定的宪法级规则放前面（稳定），动态经验规则放后面？|
| todo.md 注意力锚点 | 定期在上下文中复述当前任务和进度 | 未提及 | 长任务中是否需要类似机制防止模型注意力漂移？|
| Agent-as-a-Tool 模式 | 一个 Agent 调用另一个 Agent 作为工具 | NanoBot 有 SubagentManager | 确认 NanoBot 的 Subagent 是否足以支持 Observer/Architect 作为独立 Agent 运行 |
| 错误轨迹保留策略 | 不删除错误，让模型看到之前的失败 | 设计原则 P5 保留，但实现细节未展开 | 反思引擎在写轻量日志时是否保留完整的错误轨迹？还是只保留摘要？|
| RAG 驱动动态工具描述 | 根据任务类型变化注入相关工具 | MVP 不做动态工具注入 | NanoBot 的 Skills 系统有 always-loaded vs on-demand 机制，是否可以利用？|
| Context rot 预警阈值 | ~256K token 时性能开始下降，即使窗口有 1M | 未提及 | 是否需要在规则中设定"当对话超过 N token 时触发特殊处理"？|

### 2.2 来自 NanoBot 的未充分利用能力

| NanoBot 能力 | 当前利用计划 | 可能的更深利用 |
|-------------|------------|-------------|
| Heartbeat Service | 未明确提及 | 可作为 Observer 轻量模式和好奇心引擎的定时触发基础 |
| Cron Service | 未明确提及 | 可用于 Architect 的定时运行、每日摘要生成、信号阈值检查 |
| SOUL.md | 被规则系统替代 | 是否需要保留 NanoBot 原生的 SOUL.md 作为最基础的系统 identity，规则系统作为扩展？|
| USER.md | 被 user_preferences.md + MEMORY.md 替代 | 确认替代方案是否覆盖了 USER.md 的所有功能 |
| AGENTS.md | 未提及 | 多 Agent 协作（Observer/Architect）的上下文是否需要用到这个机制？|
| On-demand Skills | 未深入讨论 | 规则文件是否可以设计为 always-loaded（宪法级）vs on-demand（经验级，按需注入）？|
| MCP 支持 | MVP 不包含 | 是否在 Big Picture 中标记为未来扩展方向？MCP 可以让系统接入外部工具生态 |

### 2.3 来自 Claude Artifacts 沙盒架构的启发

从 Claude 的 Skill System 设计中可以借鉴：
- **技能文件 = 最佳实践提示词**：Claude 在执行任务前先读取相关的 SKILL.md，获取领域知识和最佳实践。这和我们的"规则系统"理念高度一致。
- **分层工具系统**：bash_tool、file_create、str_replace、view 等工具的分工清晰。NanoBot 的工具系统可以参考这种分层。
- **/mnt/skills/ 只读 + /home/claude 可写**：区分不可修改的基础设施和可修改的工作区域——对应我们的"硬核层不可改，规则层可改"。

### 2.4 来自多智能体协作讨论的启发

Michael 和妍芝的对话中提到了几个关键且在 v3.1 中未充分体现的点：

1. **"零沟通成本"作为 AI 多智能体的颠覆性优势**：v3.1 的 Observer 和 Architect 之间通过信号系统和文件通信，但"零沟通成本"的优势应更积极地被利用——比如让 Observer 和 Architect 之间的信息流更紧密、更实时。

2. **"人做判断、做决策、做选择"的明确定位**：v3.1 的审批分级已经体现了这一点，但可以更明确地在规则中定义"哪些类型的决策永远需要 Michael"。

3. **"购买专家决策时间"的理念**：长远来看，系统是否可以在发现自身能力不足时，建议 Michael 咨询特定领域专家？这是 Human-as-Executor 的一种高级形式。

### 2.5 来自被动收入框架的启发

**隐性知识注入（Tacit Knowledge Transfer）**是被动收入框架中最有洞察力的概念之一。这直接关系到系统的长期价值：

- v3.1 的 Observer 从 Michael 的行为中学习偏好，本质上就是在做隐性知识的逆向工程
- 但当前的学习维度（user_preferences.md）可能过于浅层——只学表面偏好，不学深层判断逻辑
- **建议**：在 Architect 的分析维度中加入"Michael 为什么做这个决策"的分析，而不只是"Michael 喜欢什么格式"

---

## 三、需要和 Michael 澄清的目标性问题

### 3.1 系统的核心身份定位

**问题**：v3.1 设计的系统，它的核心用途到底是什么？

文档中有几种不同的定位描述：
- "个人 AI 助手"（NanoBot 的定位）
- "自进化智能体系统"（自我改进的研究项目）
- "AI 同事"（像积极主动的同事一样工作）
- "AI 决策者+项目经理"（AI 思考规划，人执行 AI 做不到的部分）

这些定位之间有张力。例如：
- 如果是"个人助手"，用户体验是第一优先级，进化机制不应影响日常使用
- 如果是"研究项目"，可以容忍更多不稳定性来换取更激进的探索
- 如果是"AI 同事/决策者"，主动性和自治性需要更强

**需要明确**：Michael 希望这个系统首先是一个**好用的日常工具**，还是一个**自进化能力的实验平台**？两者的 MVP 设计优先级会不同。

### 3.2 "自进化"的边界和目标

**问题**：系统进化到什么程度算"成功"？

当前设计中，"自进化"主要体现为：
1. 经验规则的自动调优
2. 用户偏好的持续学习
3. Architect 提出系统改进方案

但原始讨论中（v1.0/v2.1）的"自进化"愿景更大：
4. 代码级自动生成新 Skill
5. 基因突变式的策略创新
6. 系统可以修改自身的架构

**需要明确**：
- v3.1 的进化范围是否限定在"规则文件和配置的调优"？
- 长期目标是否仍然包括"系统可以修改自身的代码"（Architect Level 3）？
- 如果是，如何处理自修改代码的安全性问题？

### 3.3 与 SuperBrain 业务的关系

**问题**：这个系统和 Michael 在 SuperBrain 的 AI 教育工作是什么关系？

从文档中可以推断：
- 系统可能会被用来辅助 AI 教育内容的创作和研发
- 系统的设计本身可能成为 AI 教育的教学案例
- 长期可能成为 SuperBrain 的产品基础

**需要明确**：
- MVP 阶段系统的主要使用场景是什么？日常工作助手？研究实验？教学演示？
- 是否有特定的 SuperBrain 业务场景需要优先支持？
- 垂直领域适配层（v2.1 中提到的教育领域适配）是否仍在规划中？

### 3.4 多用户 vs 单用户

**问题**：系统是只为 Michael 一人使用，还是未来需要支持多用户？

v3.1 的设计明显是单用户的（Michael 专用）。但被动收入框架和协作讨论都暗示了"这套系统可以复制给其他人"的可能性。Evolver 的 GEP 协议和"文化基因"概念也指向跨系统的经验继承。

**需要明确**：
- MVP 只需考虑单用户？
- 如果未来要支持多用户，现在需要预留什么接口？
- "文化基因"概念是否仍然有效——一个系统学到的经验能不能"移植"给新系统？

### 3.5 成本预算和运行约束

**问题**：API 调用成本的预算是多少？

v3.1 使用双模型（Opus + Gemini），每个任务后都有轻量反思（Gemini），信号触发时有深度分析（Opus），Architect 每天至少运行一次（Opus）。

**需要明确**：
- 每月的 API 预算大约是多少？
- 是否有 token 使用量的硬上限？
- 如果成本超预期，优先削减哪个环节？（轻量反思？Architect 频率？Observer 深度分析？）

---

## 四、实施路径上需要进一步讨论的技术问题

### 4.1 NanoBot 作为基座的实际可行性

**关键问题**：NanoBot 是 2026 年 2 月才发布的项目（22.3k stars），它的成熟度和稳定性如何？

需要验证的具体点：
- NanoBot 的 ContextBuilder 覆写机制是否真的灵活到可以注入复杂的规则系统？
- SubagentManager 是否支持"常驻后台观察者"这种使用模式？（NanoBot 的 Subagent 设计似乎是"执行完就结束"的一次性任务）
- NanoBot 的记忆系统（MEMORY.md + HISTORY.md + grep）在被我们大幅扩展后，是否还能保持轻量？
- NanoBot 不用 fork、只做扩展/插件的策略，在实践中能走多远？什么时候会遇到必须改核心代码的情况？

**建议**：Phase 0 中"通读 NanoBot 源码"是关键步骤。建议在 Phase 0 结束后做一次"NanoBot 可行性评估"，确认以上问题，再决定是否需要调整技术方案。

### 4.2 Observer 作为"常驻进程" vs "任务后触发"

**当前设计**：Observer 有两种模式——轻量模式（每次任务后自动触发）和深度模式（信号触发）。

**实现问题**：
- "每次任务后自动触发"在 NanoBot 中如何实现？是 hook 进 AgentLoop 的 post-processing？还是作为 MessageBus 的订阅者？
- 如果是 MessageBus 订阅者，Observer 能看到完整的任务执行轨迹（包括中间的工具调用）吗？还是只能看到最终结果？
- Observer 的 Gemini 调用是同步的（阻塞用户等待）还是异步的（后台执行）？

**建议**：需要在 Phase 3 之前明确 Observer 的技术实现方案，因为它依赖于对 NanoBot 内部事件流的理解。

### 4.3 Architect 的独立运行环境

**当前设计**：Architect 作为"独立项目运行"，有自己的工作空间和记忆。

**实现问题**：
- "独立项目"是指一个独立的 Python 进程？还是 NanoBot 内部的一个 Subagent？
- 如果是独立进程，如何与主系统共享 Observer 输出和规则文件？文件系统共享？API？
- Architect 运行时（如凌晨 2 点定时运行），主系统是否需要在线？
- Architect 修改规则文件时，如果主系统正在处理用户任务，如何避免冲突？

**建议**：需要明确 Architect 的进程模型。两个选择：
- **方案 A**：Architect 是 NanoBot 内部的 Subagent，通过 NanoBot 的消息总线触发
- **方案 B**：Architect 是独立的定时脚本（如 cron job），直接操作 workspace 目录

两种方案各有利弊，需要根据 NanoBot 的实际能力选择。

### 4.4 规则文件的动态加载

**当前设计**：规则文件是 Markdown 文件，存放在 workspace/rules/ 目录中。规则解释器读取规则文件→组装 prompt→调用 LLM。

**实现问题**：
- 规则文件在什么时间点被加载？每次用户消息到来时重新读取？还是缓存后定期刷新？
- 如果 Architect 在后台修改了某个规则文件，用户的下一条消息是否立即使用新规则？
- 所有规则文件都注入 system prompt，还是根据任务类型选择性注入？如果全部注入，token 用量如何控制？
- 规则文件之间的优先级如何处理？如果两条规则矛盾，遵循哪条？

**建议**：这是 Phase 1 的核心设计决策。规则注入策略直接影响系统行为质量和 token 成本。需要在实现前确定：
1. 规则注入方式（全量 vs 选择性）
2. 规则刷新策略（实时 vs 定期）
3. 规则冲突解决机制

### 4.5 信号系统的信噪比

**当前设计**：信号是连接 Observer 和 Architect 的桥梁。错误信号、机会信号、元信号三类。

**潜在问题**：
- 如果系统使用频率不高（如 Michael 每天只用 5-10 次），信号可能太少，Architect 无法做有意义的分析
- 如果使用频率高，信号可能太多，需要更智能的去重和优先级排序
- "信号"是一个比较抽象的概念，Gemini 在做轻量分析时是否真的能可靠地"提取信号"？

**建议**：MVP 阶段可以从最简单的信号开始——只检测"任务失败"和"用户纠正"两种显性信号。更复杂的信号类型（如 capability_gap、efficiency_opportunity）等 Observer 积累了足够数据后再引入。

### 4.6 Web Dashboard 的必要性和优先级

**当前设计**：Phase 5 实现 Web Dashboard。

**建议讨论**：
- 在 MVP 阶段，是否真的需要 Web Dashboard？Michael 可以直接查看 workspace/ 目录下的文件来了解系统状态
- 如果 Architect 的提案和报告都通过 Telegram 推送，Dashboard 的核心价值是什么？主要是趋势图表？
- Dashboard 的开发时间（2-3 天）是否值得？这个时间可以用来更深入地打磨 Observer/Architect 的质量
- 替代方案：Architect 每天生成一份 Markdown 格式的"系统状态报告"，推送到 Telegram 或存放在 workspace/ 中

---

## 五、跨文档一致性问题

### 5.1 技术栈选择的变迁

| 版本 | 推荐技术栈 | 变化原因 |
|------|-----------|---------|
| v1.0 doc3 | Node.js/TypeScript | "参考 OpenClaw 的选择" |
| v2.0 | Python + litellm + sqlite-vec | "Python 极简原则" |
| v2.1 | Python 生态 | 确认 Michael 偏好 |
| v3.1 | Python + NanoBot + Flask/FastAPI | NanoBot 确定为基座 |

**问题**：v2.0/v2.1 中计划使用 litellm 做多模型统一接口。NanoBot 本身也通过 LiteLLM 提供统一接口。是否直接使用 NanoBot 的 Provider Registry？

### 5.2 设计原则的数量和编号

- v1.0：6 条原则
- v2.0：8 条（新增 代码即交互、最小可行认知）
- v2.1：9 条（新增 Human-as-Executor，拆分好奇心）
- v3.0：12 条（新增 规则即程序、自我定义、积极同事）
- v3.1：15 条（新增 信号驱动、爆炸半径、分离观察与行动）

**问题**：15 条原则是否太多？是否有些可以合并？比如"减法优于加法"（P3）和"爆炸半径优于权限控制"（P14）都在讲控制复杂度。

### 5.3 记忆系统的演进

| 版本 | 记忆设计 |
|------|---------|
| v1.0 | 四层（工作/情节/语义/程序性）+ 向量+BM25 混合搜索 |
| v2.1 | 同 v1.0 + 冷启动种子 + 记忆衰减预留 + 双向迁移 |
| v3.1 MVP | MEMORY.md + JSONL 对话记录 + 关键词匹配 |

这是一个巨大的简化。虽然 MVP 简化是合理的，但需要确保：
- v3.1 的 MEMORY.md 设计是否为未来升级到向量搜索预留了接口？
- JSONL 格式是否支持未来添加 access_count、freshness_score 等衰减字段？

---

## 六、具体的行动建议

### 6.1 在 MVP 实施前需要完成的决策

| # | 决策项 | 影响范围 | 建议优先级 |
|---|-------|---------|-----------|
| 1 | 系统核心身份定位（日常工具 vs 研究平台） | 所有设计取舍 | 最高 |
| 2 | NanoBot 可行性验证（Phase 0 后） | 技术方案是否需要调整 | 最高 |
| 3 | 规则注入策略（全量 vs 选择性） | Phase 1 实现 | 高 |
| 4 | Architect 进程模型（Subagent vs 独立进程） | Phase 4 实现 | 高 |
| 5 | 初始规则文件内容的编写 | Phase 1 质量 | 高 |
| 6 | API 成本预算 | 模型使用策略 | 中 |
| 7 | Web Dashboard 是否在 MVP 中 | 实施计划 | 中 |
| 8 | 种子记忆内容 | 冷启动体验 | 中 |

### 6.2 建议写入 Big Picture 但 MVP 不实现的设计

以下设计应在 Big Picture 文档中保留，作为 Architect 后续进化的方向参考：

1. CODER Agent + 代码到技能自动提炼
2. 难度路由器（三档路由 + 可进化参数）
3. 好奇心引擎 v2（意图池 + AI 自主探索）
4. Human-as-Executor 完整模式
5. 四层用户模型 + 信念更新
6. 向量搜索 + BM25 混合检索
7. Compaction 质量保障（关键信息锁定 + 认知层级转化 + 压缩验证）
8. Scattered-and-Stacked 并行推理
9. 多智能体辩论（DOWN 框架自适应激活）
10. 基因突变 + A/B 测试
11. 主动遗忘机制（记忆衰减）
12. 正反馈循环量化（健康度监控）
13. 竞争性自评估
14. 垂直领域适配层
15. 文化基因 / 跨系统经验继承

### 6.3 建议合并到 v3.1 设计中的小改进

这些不增加 MVP 复杂度，但提升设计完整性：

1. **在规则注入时考虑 KV-cache 友好性**：宪法级规则固定在 system prompt 前部，经验级规则在后部动态追加
2. **在 MEMORY.md 的 User Profile 中增加"隐性知识"section**：记录 Michael 的深层判断逻辑，不只是表面偏好
3. **在 Architect 提案模板中增加"需要人类执行的行动"字段**：为 Human-as-Executor 预留入口
4. **在 Observer 轻量日志中保留关键错误的完整轨迹**：而不只是"成功/失败"的二元判断
5. **利用 NanoBot 的 Heartbeat 服务**：作为 Observer 和 Architect 的定时触发基础设施
6. **利用 NanoBot 的 Cron 服务**：作为 Architect 每日运行、每日摘要生成的基础设施

---

## 七、总结：v3.1 的整体评价

**做对的事情**：
- "规则即程序，代码即基座"的范式转变是正确的方向
- Observer/Architect 分离设计优雅
- 信号驱动进化比定时触发更高效
- 爆炸半径 + 自动回滚的安全设计务实
- 以 NanoBot 为基座，"不 fork、只扩展"的策略聪明
- "进化型 MVP"理念——从第一天就有自我改进闭环

**可能的风险**：
- v3.1 相对于 v2.1 做了大量简化，某些被简化掉的设计（好奇心引擎、用户模型深度、代码技能提炼）可能是长期差异化价值的来源
- NanoBot 是很新的项目，其稳定性和可扩展性尚未经过大规模验证
- 规则系统的有效性高度依赖初始规则文件的质量——这些规则文件的编写本身就是一个需要大量思考的设计工作
- 系统的核心用途定位尚不够明确，这会影响 MVP 的取舍

**核心方向是对的**：v3.1 在"可执行性"和"进化潜力"之间取得了不错的平衡。关键是确保被简化掉的设计不是被遗忘，而是在 Big Picture 中保留，等待 Architect 在数据驱动下逐步引入。
