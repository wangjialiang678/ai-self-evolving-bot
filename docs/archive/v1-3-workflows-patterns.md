# 自进化智能体系统：动态工作流与行为模式

> **文档版本**: v1.0  
> **文档性质**: 运行时行为设计文档  
> **配套文档**: [系统架构概览](doc1) | [核心子系统设计](doc2)

---

## 一、系统生命周期：从冷启动到自我进化

### 1.1 整体生命周期

系统有五个阶段，每个阶段系统的行为特征不同：

```
阶段 1：初生期（Bootstrap）
  持续时间：系统部署后的前 1-3 天
  特征：
    - 没有用户模型，所有偏好使用默认值
    - 没有学习到的技能，依赖内置技能和通用推理
    - 反思引擎在积极收集数据但尚未产出可靠策略
    - 好奇心引擎活跃——频繁向用户提问以建立基础理解
  系统行为：
    - 对每个任务都做完整反思（即使任务很小）
    - 主动询问用户的工作习惯、偏好、关注领域
    - 保守执行（更多使用"执行前确认"模式）

阶段 2：学习期（Learning）
  持续时间：部署后 3-30 天
  特征：
    - 用户模型开始成形（部分偏好已达到中等置信度）
    - 反思引擎开始产出策略建议，但尚未达到沉淀阈值
    - 技能库开始积累（3-10 个新技能处于试用期）
  系统行为：
    - 开始根据用户偏好调整输出格式和风格
    - 对常见任务类型形成初步的处理流程
    - 仍然频繁做反思，但频率开始降低
    - 好奇心引擎从"建立基础理解"转向"填补特定缺口"

阶段 3：稳定期（Stable）
  持续时间：30 天之后
  特征：
    - 用户模型成熟（主要偏好置信度 > 0.8）
    - 多个技能已通过验证进入 active 状态
    - 进化规则库稳定，大部分常见场景有明确策略
  系统行为：
    - 执行效率高，大部分任务可以直接复用已有技能
    - 反思引擎转为"异常驱动"——只在失败或异常时做深度反思
    - 好奇心引擎安静——只在遇到全新场景时触发
    - 达到突变的前提条件，开始尝试优化

阶段 4：进化期（Evolving）
  持续时间：稳定期之后持续进行
  特征：
    - 部分技能开始经历突变和优化
    - 系统能力逐步提升，处理新任务类型的速度加快
    - 定期回顾识别出系统性改进机会
  系统行为：
    - A/B 测试突变策略
    - 跨任务的模式识别（发现不同任务类型之间的共性）
    - 主动建议用户"我发现了一种更好的方式来做 X"
    
阶段 5：专精期（Mastery）
  持续时间：大量使用后
  特征：
    - 对用户的特定领域形成深度理解
    - 技能库高度定制化
    - 系统的行为风格与用户高度契合
  系统行为：
    - 能预判用户需求（"你上次提到要做 X，需要我继续吗？"）
    - 对新任务能快速找到最优策略（通过组合已有技能）
    - 突变从"参数微调"转向"策略创新"
```

### 1.2 日常运行节奏

```
每日时间线：

[系统启动 / 新的一天]
  ├─ 加载今日和昨日的 daily log
  ├─ 加载 MEMORY.md 到索引
  ├─ 检查是否有未完成的任务
  └─ 如果有定时任务 → 放入事件队列

[用户交互时段]
  ├─ 接收用户消息 → 事件总线 → Agent Loop
  ├─ 执行任务 → 记录到 daily log
  ├─ 任务完成 → 触发反思
  └─ 用户反馈 → 更新用户模型

[非交互时段（后台）]
  ├─ 心跳任务（如检查邮件、监控变化）
  ├─ 记忆索引维护（新内容同步到向量/全文索引）
  └─ 定时的 Compaction（如果 session 较长）

[每日结束]
  ├─ 触发"每日回顾"反思
  │   └─ 分析今日所有任务，识别系统性模式
  ├─ 进化引擎处理当日反思
  │   ├─ 规则沉淀（如果有候选规则达到阈值）
  │   ├─ 突变评估（如果有正在测试的突变）
  │   └─ 用户模型更新汇总
  └─ 清理和归档
      ├─ 超过 30 天的 daily log → 生成摘要后归档
      └─ 语义记忆去重和合并
```

---

## 二、典型场景工作流

### 场景 A：首次使用——建立关系

```
触发：新用户首次与系统交互

[用户]: "你好，帮我分析一下 AI 教育市场的趋势"

系统内部流程：

1. 事件总线接收 USER_MESSAGE 事件
   session_id: 新建
   priority: HIGH

2. Agent 编排器启动 PLANNER Agent
   PLANNER 分析任务 → 识别为"市场调研"类型
   同时注意到：这是新用户，用户模型为空

3. 好奇心引擎 Pre-Inference 检测
   发现：
   - 不知道用户关注 AI 教育的哪个细分领域
   - 不知道用户需要什么深度的分析
   - 不知道用户的背景（投资者？教育者？创业者？）
   
4. 系统决策：先快速回应，同时嵌入关键问题
   
[系统回复]:
   "好的，我来帮你分析 AI 教育市场趋势。为了让分析更有针对性，
    有几个问题想先确认：
    
    1. 你更关注 K-12 还是高等教育/成人教育？
    2. 分析的目的是什么——投资决策、产品规划、还是行业了解？
    3. 希望分析多深入——快速概览（10分钟），还是深度报告（1小时）？
    
    在你回答之前，我先开始收集一些基础数据。"

5. 同时启动 RESEARCHER Agent 开始基础搜索
   （不等待用户回答，先做通用性的市场数据收集）

6. 用户回答后：
   - 好奇心引擎解析回答，更新用户模型
   - PLANNER 根据新信息调整任务分解
   - RESEARCHER 调整搜索方向

7. 任务完成后的反思：
   反思引擎分析整个流程
   提取：
   - "用户是教育从业者（非投资者），关注 K-12"
   - "用户偏好对比表格形式的分析"（从用户的追问推断）
   
   写入用户模型和语义记忆
```

### 场景 B：任务执行中被用户打断

```
触发：用户在系统执行任务过程中发送新消息

[用户]: "帮我写一份产品需求文档"
[系统]: "好的，开始编写..."（内部启动了 PLANNER → EXECUTOR 流程）

... 系统正在执行第 3 步（市场调研）...

[用户]: "等一下，需求文档里要特别强调安全性，我们的客户对数据隐私非常敏感"

系统内部流程：

1. 事件总线接收新的 USER_MESSAGE 事件
   type: USER_MESSAGE
   sessionId: 当前 session
   priority: HIGH（用户消息优先级始终高于后台任务）

2. Agent Loop 的下一个迭代
   步骤 1（收集事件）：发现新的用户消息事件
   步骤 2（组装上下文）：
     上下文引擎在上下文中插入：
     - [用户中断] "需求文档里要特别强调安全性..."
     - 同时保留当前任务的进度信息
     
3. 模型推理时看到：
   - 正在执行的任务（写产品需求文档）
   - 已完成的步骤（1-3 步）
   - 用户的新要求（强调安全性）
   
   模型决策：
   - 不需要重启任务
   - 修改后续步骤的策略，在所有章节中加入安全性考量
   - 回到已完成的章节，补充安全性相关内容
   
4. 系统回复：
   "收到，我会在整个文档中突出数据隐私和安全性。
    具体来说：
    - 在功能需求中增加数据安全相关的非功能性需求
    - 在用户故事中加入安全场景
    - 增加独立的'安全与合规'章节
    正在调整..."

5. 反思记录：
   记录这次中断事件
   提取策略："需求文档类任务，应在开始前主动询问是否有特殊合规要求"
   
关键点：整个中断处理不需要任何特殊代码。
事件驱动 + Agent Loop 天然支持这种模式。
```

### 场景 C：从失败中学习并进化

```
触发：系统执行任务失败，触发反思和进化流程

[用户]: "帮我用 Python 写一个自动发邮件的脚本"

第一次尝试：
  EXECUTOR Agent 生成代码，但用了一个已弃用的库
  用户测试后报告："运行报错了"

1. 错误反思（立即触发）
   反思引擎分析：
   - 错误类型：TOOL_MISUSE
   - 根因：使用了 smtplib 的旧 API，Python 3.12 中已更改
   - 策略建议："Python 邮件脚本应检查运行环境版本，使用最新兼容 API"
   - 置信度：MEDIUM

2. Agent Loop 继续（带着错误轨迹）
   上下文中现在包含：
   - 原始错误信息
   - 反思引擎的诊断
   - 修正方向
   
   EXECUTOR 生成修正后的代码
   用户测试："这次可以了，谢谢"

3. 任务完成反思
   反思引擎分析完整流程：
   - 结果：PARTIAL（最终成功但经历了一次失败）
   - 效率损失：第一次尝试浪费了约 3000 token
   - 策略建议（确认）：
     "Python 脚本任务，应先确认目标 Python 版本再选择库"
     置信度：HIGH（因为已经验证了修正有效）

4. 情节记忆记录
   daily log 中记录完整过程，包括失败和修正

5. 进化引擎处理
   这条策略建议是首次出现，标记为"待验证"
   在未来的 Python 脚本任务中观察是否有效

... 两周后，类似场景出现了 3 次，反思引擎 3 次提出同样的建议 ...

6. 规则沉淀
   达到重复验证阈值（3 次）
   进化引擎将策略写入程序性记忆：
   
   # skills/learned/python_scripting_v1.yaml
   skill_id: "python_scripting_v1"
   name: "Python 脚本编写"
   steps:
     - action: "确认环境"
       details: "先询问用户的 Python 版本和运行环境"
     - action: "选择库"
       details: "根据版本选择兼容的库，优先使用标准库"
     - action: "生成代码"
       details: "包含错误处理和版本检查"
     - action: "提供测试指令"
       details: "给用户明确的测试步骤"
   learned_from: ["reflection_012", "reflection_018", "reflection_023"]
   success_rate: 1.0  # 应用策略后 3/3 成功
   status: active

... 一个月后，该技能的使用次数达到 15 次，成功率 93% ...

7. 基因突变触发
   进化引擎检测到该技能达到突变条件（成功率 > 85%，使用 > 10 次）
   生成突变方案：
   
   突变 A（参数微调）：
     "在'选择库'步骤中，增加'优先使用异步库'的指导"
     原因：分析成功案例发现，使用异步库的版本用户反馈更好
     
   突变 B（步骤新增）：
     "增加'生成 requirements.txt'步骤"
     原因：3 次用户追问了依赖安装问题
   
   开始 A/B 测试...
```

### 场景 D：主动好奇心——系统发起对话

```
触发：系统在非交互时段发现有价值的信息

背景：用户之前让系统持续关注"AI 教育政策变化"

1. 心跳任务（后台定时触发）
   RESEARCHER Agent 按计划执行定期搜索
   搜索"AI education policy 2026"
   
2. 发现新信息
   搜索结果中出现一条：某地教育部门发布了新的 AI 教育指导意见
   
3. 相关性评估
   好奇心引擎分析：
   - 这条信息与用户之前的关注点高度相关（相关性 > 0.9）
   - 用户模型显示用户关注 AI 教育政策
   - 这是新发布的信息（用户可能还不知道）
   
4. 决策：主动通知用户
   
   先做深度研究：
   - 读取原始政策文件
   - 分析对 AI 教育机构的具体影响
   - 整理关键要点
   
5. 主动发送消息（通过用户的通讯渠道，如 Telegram）

   "发现一条可能对你有用的信息：
    [某地] 今天发布了 AI 教育指导意见，主要内容包括：
    1. [要点一]
    2. [要点二]
    3. [要点三]
    
    这对教育机构的影响是 [简要分析]。
    需要我做更详细的分析吗？"

6. 用户响应处理
   如果用户说"详细分析一下" → 启动深度研究任务
   如果用户说"知道了" → 记录用户已知晓
   如果用户没有回复 → 不追问，但在语义记忆中标记这条信息
   
7. 反思和进化
   记录用户的响应模式
   如果用户经常对主动通知表示感谢 → 增加主动通知频率
   如果用户经常忽略 → 降低主动通知频率或调整通知阈值
```

### 场景 E：跨任务模式发现——系统级进化

```
触发：每日回顾时，反思引擎发现跨任务的系统性模式

每日回顾分析：

今日任务列表：
  1. 帮用户写会议纪要 → 成功（15min）
  2. 帮用户分析数据 → 成功（20min）
  3. 帮用户写邮件回复 → 成功（5min）但用户做了大量修改
  4. 帮用户做竞品分析 → 成功（30min）
  5. 帮用户写项目总结 → 成功（10min）但用户追问了 3 次

反思引擎做跨任务模式分析：

Prompt：
  "以下是今日 5 个任务的执行记录和用户反应。
   请分析是否存在跨任务的系统性模式——
   特别关注：重复出现的低效模式、用户反馈中的共性、
   以及可以统一改进的策略。"

分析结果：
  发现 1（跨任务模式）：
    任务 3 和任务 5 都涉及"代表用户表达观点"，
    而用户在两次都做了修改或追问。
    推断：系统在"代表用户立场写作"方面的品味模型不够精准。
    建议：下次此类任务前，主动询问用户的立场和语气偏好。
    
  发现 2（效率模式）：
    所有涉及网页搜索的任务，搜索步骤平均占总时间的 40%。
    其中约一半的搜索结果与最终输出无关。
    建议：优化搜索策略——先用少量搜索做初步判断，
    再有针对性地做深度搜索。
    
  发现 3（用户模型更新）：
    从任务 3 的用户修改中分析出：
    用户在邮件中倾向使用"建议"而非"应该"，
    倾向用具体数据支撑观点而非一般性陈述。
    更新用户模型的"工作沟通风格"维度。

进化引擎处理：
  - 发现 1 → 生成新的策略候选规则
  - 发现 2 → 对搜索相关的技能启动参数微调
  - 发现 3 → 用户模型更新（confidence 提升）
```

---

## 三、关键行为模式

### 3.1 渐进式信任建立

系统与用户之间的信任是逐步建立的。系统通过以下机制管理自主权的渐进提升：

```
信任度评估维度：
  
  1. 任务类型的历史表现
     连续 N 次在某类任务上成功 → 该类任务的信任度 +1
     失败或用户大量修改 → 信任度 -2
     
  2. 用户的明确授权
     用户说"以后这类事情你直接做就行" → 大幅提升
     用户说"这个让我先看看" → 降低
     
  3. 操作风险等级
     只读操作（搜索、分析）→ 低风险，自主权高
     可逆写操作（生成文档）→ 中风险，执行后通知
     不可逆操作（发送邮件）→ 高风险，始终执行前确认

信任度到自主权的映射：

  信任度 0-3（初生期）：
    所有任务 → 执行前确认
    
  信任度 4-7（学习期）：
    低风险任务 → 完全自主
    中风险任务 → 执行后通知
    高风险任务 → 执行前确认
    
  信任度 8+（稳定期及以后）：
    低风险任务 → 完全自主
    中风险任务 → 完全自主
    高风险任务 → 执行后通知（但用户可配置为"执行前确认"）
    
  用户可以随时手动覆盖任何操作的自主权级别
```

### 3.2 注意力漂移防御

Agent 在执行长任务时，模型可能"忘记"自己在做什么。系统通过以下机制防御：

```
机制 1：任务锚点复述（来自 Manus 的 todo.md）
  频率：每 5 次工具调用后
  方式：在上下文中重新插入任务描述和当前进度
  
  格式：
    "=== 任务提醒 ===
     你正在执行：{任务描述}
     当前步骤：{当前步骤}（第 {N}/{Total} 步）
     已完成：{完成的步骤摘要}
     下一步应该做：{下一步描述}
     ==================="

机制 2：重复行为检测
  监控：Agent 的最近 5 次工具调用
  检测：如果相同工具被调用 3 次以上且参数相似 → 判定为"卡住"
  处理：
    a. 向上下文注入提示："你似乎在重复同样的操作。请重新评估当前策略。"
    b. 如果仍然重复 → 强制切换策略或请求人类帮助

机制 3：多样性注入（来自 Manus）
  当系统检测到模型连续 N 次选择同一类型的工具或生成同质化的输出时，
  在上下文中注入"请考虑不同的方法"的提示，打破模式僵化。
  
  实现方式：在上下文末尾追加：
    "注意：你之前的 {N} 次操作都使用了相似的方法。
     请评估是否有其他更有效的途径。"
```

### 3.3 优雅降级

当系统遇到能力边界时，不是崩溃或给出低质量结果，而是优雅降级：

```
降级策略优先级：

1. 切换方法
   原方法不可用 → 尝试替代方法
   示例：API 不可用 → 改为网页抓取 → 改为搜索公开信息
   
2. 降低精度
   无法给出精确答案 → 给出范围或估算
   示例："无法获取精确数据，但根据公开信息估计在 X-Y 之间"
   
3. 分解和部分完成
   无法完成整个任务 → 完成能完成的部分，标明未完成的部分
   示例："以下 5 个维度中，我完成了 3 个的分析。
         第 4 和第 5 个需要访问你的内部系统，需要你的协助。"
   
4. 请求帮助
   以上都不行 → 通过好奇心引擎请求人类协助
   明确说明：需要什么帮助、为什么自己做不了、预计帮助后能完成到什么程度
   
5. 诚实放弃
   如果任务确实超出系统能力 → 诚实告知
   说明：尝试了什么、为什么失败、建议用户寻找什么替代方案
```

---

## 四、进化行为的完整生命周期

### 4.1 一条规则从诞生到进化的完整故事

以下是一条策略规则的完整生命周期示例：

```
第 1 天：初始经验
  任务：帮用户写技术博客
  结果：成功，但用户反馈"太长了"
  反思：策略建议 → "技术博客应控制在 1500 字以内"
  状态：observation（仅记录，不生效）

第 5 天：重复验证
  又有 2 次技术写作任务，用户都要求缩短
  反思：同一策略建议出现 3 次
  状态：candidate（候选规则，等待进化引擎确认）

第 6 天：进化引擎处理
  检查候选规则：3 次独立反思支持，无矛盾证据
  决策：创建新规则
  
  # evolution/rules/active_rules.yaml 新增：
  - rule_id: "writing_length_001"
    rule: "技术博客类写作，默认控制在 1500 字以内"
    status: probation  # 试用期
    confidence: 0.75
    evidence: ["reflection_008", "reflection_012", "reflection_015"]
    validation_target: "5 次相关任务后评估"
    created: "2026-02-20"

第 7-14 天：试用期验证
  规则注入上下文 → 5 次技术写作任务中使用
  结果：4 次用户满意，1 次用户要求"这篇可以写长一些"
  
第 15 天：状态升级
  成功率 80%（4/5）> 最低阈值 70%
  进化引擎决策：status: active
  同时记录例外情况："用户有时会要求更长的文章"

第 45 天：突变触发
  技能使用次数达到 15 次，成功率 87%
  进化引擎生成突变方案：
  
  突变 A："将固定 1500 字改为'先问用户期望的长度'"
  突变 B："根据主题复杂度自动调整（简单主题 1000 字，复杂主题 2000 字）"
  
  开始 A/B 测试
  
第 45-60 天：突变测试
  突变 A 测试结果：成功率 93%（14/15）
  突变 B 测试结果：成功率 80%（12/15）
  原版成功率：87%

第 61 天：突变评估
  突变 A 显著优于原版（93% vs 87%）→ KEEP
  突变 B 无显著改善（80% vs 87%）→ DISCARD
  
  更新技能：
  - rule_id: "writing_length_001"
    rule: "技术写作前，先确认用户期望的篇幅"
    version: 2
    previous_version: "默认控制在 1500 字以内"
    mutation_source: "mutation_test_023"
    status: active
    confidence: 0.93
```

### 4.2 进化的安全保障

```
安全检查点：

检查点 1：规则生成时
  - 新规则不能与系统安全规则冲突
  - 新规则不能提升操作的自主权级别（只有用户可以）
  - 新规则必须有明确的回滚方案

检查点 2：突变生成时
  - 突变方案由 CRITIC Agent 审查
  - 高风险突变（类型 D：全新策略）需要人类批准
  - 突变不能修改安全边界或监督层级

检查点 3：突变测试时
  - 如果突变版本在测试中导致了严重错误 → 立即停止测试
  - 如果突变版本连续 3 次表现差于原版 → 提前终止测试

检查点 4：持续监控
  - 即使规则已经 active，如果连续 3 次失败 → 自动降级为 probation
  - 如果降级后仍然表现不佳 → 自动移入 deprecated
  - 所有变更都记录在 strategy_log.jsonl，支持完整审计
```

---

## 五、数据流与通信协议

### 5.1 组件间消息格式

系统内部组件之间使用统一的消息格式通信：

```yaml
# 通用消息格式
message:
  id: "msg_20260214_001"
  from: "reflection_engine"      # 发送者
  to: "evolution_engine"         # 接收者
  type: "STRATEGY_PROPOSAL"      # 消息类型
  priority: NORMAL               # HIGH | NORMAL | LOW
  timestamp: "2026-02-14T10:30:00Z"
  payload:
    # 消息体（结构根据 type 不同而不同）
    strategy: "技术写作前先确认篇幅"
    confidence: 0.85
    evidence_count: 3
  correlation_id: "task_001"     # 关联的任务 ID
  ttl: 3600                      # 消息存活时间（秒）
```

### 5.2 完整的任务执行数据流

```
用户消息
  │
  ▼
[事件总线] ── 事件 ──► [Agent 编排器]
  │                        │
  │                    任务分解
  │                        │
  │                        ▼
  │                   [PLANNER Agent]
  │                        │
  │                   生成子任务列表
  │                        │
  │            ┌───────────┼───────────┐
  │            ▼           ▼           ▼
  │      [EXECUTOR]   [RESEARCHER]  [EXECUTOR]
  │         │              │            │
  │         │              │            │
  │    ┌────┘         ┌────┘       ┌────┘
  │    ▼              ▼            ▼
  │ [上下文引擎]    [上下文引擎]  [上下文引擎]
  │    │              │            │
  │    │ 组装上下文    │            │
  │    │              │            │
  │    ▼              ▼            ▼
  │ [LLM 推理]    [LLM 推理]   [LLM 推理]
  │    │              │            │
  │    │ 工具调用      │ 搜索       │ 工具调用
  │    ▼              ▼            ▼
  │ [工具注册表]  [研究模块]    [工具注册表]
  │    │              │            │
  │    │ 结果          │ 结果       │ 结果
  │    ▼              ▼            ▼
  │    └──────────────┼────────────┘
  │                   │
  │              汇总结果
  │                   │
  │                   ▼
  │            [CRITIC Agent]
  │                   │
  │              质量检查
  │                   │
  │                   ▼
  │              最终输出
  │                   │
  │         ┌─────────┴─────────┐
  │         ▼                   ▼
  │    [回复用户]          [反思引擎]
  │                            │
  │                       生成反思报告
  │                            │
  │                            ▼
  │                       [进化引擎]
  │                            │
  │                  ┌─────────┼─────────┐
  │                  ▼         ▼         ▼
  │             规则沉淀    突变评估   用户模型更新
  │                  │         │         │
  │                  ▼         ▼         ▼
  │            [记忆系统]  [技能库]  [用户模型]
  │
  ▼
[记忆系统] ── 写入 daily log ──► [持久化存储]
```

---

## 六、配置与调参指南

### 6.1 关键参数一览

以下参数控制系统的核心行为，可以根据使用场景调整：

```yaml
# config/system.yaml

# 上下文引擎参数
context:
  budget_ratio: 0.75           # 上下文预算 = 窗口大小 × 此值
  system_prompt_ratio: 0.15    # 系统 prompt 占预算的比例
  memory_ratio: 0.20           # 相关记忆占预算的比例
  history_ratio: 0.30          # 对话历史占预算的比例
  
# Compaction 参数
compaction:
  soft_threshold_ratio: 0.85   # 触发 Compaction 的 token 占比
  reserve_tokens: 4096         # 始终保留的空闲 token 数
  keep_recent_turns: 5         # Compaction 时保留最近 N 轮对话
  summary_ratio: 0.15          # 摘要长度 = 原内容 × 此值

# 反思引擎参数  
reflection:
  post_task: true              # 任务完成后是否反思
  on_error: true               # 错误发生时是否立即反思
  daily_review: true           # 是否做每日回顾
  daily_review_time: "23:00"   # 每日回顾时间
  min_task_duration: 60        # 只对耗时超过 N 秒的任务做反思

# 进化引擎参数
evolution:
  crystallization_threshold: 3  # 策略建议需要重复 N 次才沉淀为规则
  mutation_success_threshold: 0.85  # 触发突变的最低成功率
  mutation_min_samples: 10     # 触发突变的最低使用次数
  mutation_test_count: 10      # 突变 A/B 测试的任务数
  mutation_improvement_threshold: 0.05  # 突变需要比原版好 N% 才保留

# 好奇心引擎参数
curiosity:
  proactive_notification: true  # 是否允许主动通知
  min_relevance_for_notification: 0.9  # 主动通知的最低相关性阈值
  max_questions_per_task: 2    # 每个任务最多问用户几个问题
  question_timeout: 3600       # 等待用户回答的超时（秒）
  quiet_hours:                 # 免打扰时段
    start: "22:00"
    end: "08:00"

# 用户模型参数
user_model:
  min_confidence_to_apply: 0.6  # 偏好置信度低于此值不注入上下文
  confirmed_threshold: 0.9      # 超过此值视为"已确认偏好"
  contradiction_alert: 0.3      # 矛盾比超过此值时标记为"需确认"
  
# 安全参数
safety:
  max_tool_calls_per_task: 50  # 单任务最大工具调用次数
  max_tokens_per_task: 100000  # 单任务最大 token 消耗
  require_confirmation_for:    # 始终需要人类确认的操作
    - "send_email"
    - "delete_file"
    - "financial_transaction"
  mutation_auto_approve_types:  # 允许自动执行的突变类型
    - "PARAMETER_TUNE"         # 参数微调
    - "STEP_REORDER"           # 步骤重排
  mutation_require_approval:    # 需要人类批准的突变类型
    - "NEW_STRATEGY"           # 全新策略
```

### 6.2 不同使用场景的推荐配置

```yaml
# 个人助手场景（高自主权、积极进化）
personal_assistant:
  curiosity.proactive_notification: true
  evolution.mutation_success_threshold: 0.80  # 更激进的突变
  safety.require_confirmation_for: ["financial_transaction"]  # 最少确认

# 工作助手场景（中等自主权、稳健进化）
work_assistant:
  curiosity.proactive_notification: true
  curiosity.quiet_hours: {start: "18:00", end: "09:00"}
  evolution.mutation_success_threshold: 0.90  # 保守的突变
  safety.require_confirmation_for: ["send_email", "modify_code", "financial"]

# 教育辅助场景（低自主权、重视解释）
education_assistant:
  curiosity.proactive_notification: false  # 不主动打扰学生
  curiosity.max_questions_per_task: 3      # 可以多问问题（教学目的）
  evolution.mutation_require_approval: ["ALL"]  # 所有突变需教师批准
  reflection.post_task: true               # 每次都反思（用于教学评估）
```

---

## 七、实现路径建议

### 7.1 分阶段实现计划

考虑到系统的复杂度，建议分四个阶段实现：

```
第一阶段：基础骨架（2-4 周）
  实现内容：
    - 事件总线（基于内存的简单实现）
    - 基础 Agent Loop（单 Agent，Think-Act 循环）
    - 基础上下文引擎（固定模板，无动态优化）
    - 基础记忆系统（仅工作记忆 + 情节记忆的 daily log）
    - 工具注册表（硬编码工具列表）
  验证标准：
    - 能接收用户任务、调用工具、返回结果
    - 能记录执行日志
    
第二阶段：认知能力（4-6 周）
  实现内容：
    - 上下文引擎的完整实现（token 预算、动态组装、Compaction）
    - 完整记忆系统（四层记忆 + 混合搜索）
    - 研究模块（网页搜索 + 文档阅读）
    - 多 Agent 编排（PLANNER + EXECUTOR + RESEARCHER）
    - 动态工具注入（RAG 驱动）
  验证标准：
    - 能处理复杂的多步任务
    - Compaction 后不丢失关键信息
    - 记忆检索的准确性 > 80%

第三阶段：进化能力（4-6 周）
  实现内容：
    - 反思引擎（五维反思 + 定期回顾）
    - 进化引擎（规则沉淀 + 基因突变 + A/B 测试）
    - 用户模型（四层模型 + 信念更新算法）
    - 好奇心引擎（缺口检测 + 主动提问）
  验证标准：
    - 能从失败中提取策略并在后续任务中应用
    - 用户模型的准确性随使用逐步提升
    - 突变系统能产生有效改进

第四阶段：产品化（4-8 周）
  实现内容：
    - 多通道支持（Telegram/WhatsApp/Slack 等）
    - 持久化 Gateway 和 session 管理
    - 安全和权限系统
    - 透明度界面（让用户查看记忆、规则、用户模型）
    - 性能优化（KV-cache 命中率、并发处理）
  验证标准：
    - 可以 7×24 小时稳定运行
    - 用户可以通过即时通讯工具自然交互
    - 安全边界有效且不影响正常使用
```

### 7.2 技术选型建议

```
运行时环境：
  推荐：Node.js/TypeScript（参考 OpenClaw 的选择）
  原因：
    - 天然的异步事件驱动模型
    - 丰富的即时通讯 SDK 生态
    - TypeScript 的类型系统有助于维护复杂的数据结构
  替代：Python（如果团队更熟悉）
    - 需要额外使用 asyncio 处理异步
    - 但 LLM 相关的库生态更丰富

LLM 接口：
  推荐：Anthropic Claude API（主推理）+ 开源模型（辅助任务）
  原因：
    - Claude 的长上下文和工具调用能力成熟
    - 辅助任务（摘要、分类）可以用更便宜的模型

向量数据库：
  推荐：sqlite-vec（参考 OpenClaw）
  原因：
    - 本地优先，无需外部服务
    - 与 SQLite FTS5 天然集成（混合搜索）
    - 轻量级，适合个人/小团队使用

消息通道：
  推荐：先实现 Telegram Bot API（最简单）
  然后扩展到 WhatsApp（Baileys）、Slack、Discord

文件存储：
  推荐：本地文件系统 + Markdown/YAML/JSONL
  原因：
    - 人类可读、可审查
    - 版本控制友好（可以用 Git 追踪变化）
    - 不需要额外的数据库服务
```

---

## 八、设计的开放问题

以下问题在当前设计中尚未完全解决，需要在实现过程中持续探索：

```
问题 1：进化的速度如何控制？
  太快的进化可能导致系统不稳定（不断改变规则）
  太慢的进化会错过改进机会
  需要实验确定最佳的突变频率和测试周期

问题 2：用户模型的深度与隐私如何平衡？
  更深的用户理解需要更多的数据收集和推断
  但用户可能不希望系统对自己了解太多
  需要提供明确的隐私控制和透明度保证

问题 3：多用户场景如何处理？
  当前设计主要面向单用户
  如果多人共享一个系统实例，用户模型和技能库是否需要隔离？
  共享的技能（某个用户发现的好策略）是否可以跨用户传播？

问题 4：长期漂移如何检测？
  经过数月的进化，系统的行为可能逐渐偏离初始设定
  是否需要定期的"全局审计"来检查整体方向？
  如何平衡适应性和一致性？

问题 5：进化的进化
  进化引擎本身的参数（突变阈值、测试周期等）是否也应该自我优化？
  这是一个元进化问题——如果实现，需要特别注意稳定性
```

---

> **文档结束**  
> 本设计文档包含三个部分：  
> 1. [系统架构概览](doc1) — 设计哲学、三层架构、十大核心组件  
> 2. [核心子系统设计](doc2) — 每个组件的内部设计、算法和接口规范  
> 3. [动态工作流与行为模式](doc3)（本文档）— 运行时流程、典型场景、进化生命周期
