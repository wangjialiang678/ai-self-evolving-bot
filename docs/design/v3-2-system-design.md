# V3.2 自进化智能体系统 — 完整设计方案

> **版本**: 3.2
> **日期**: 2026-02-23
> **状态**: 设计稿
> **前序**: 基于 V3.1 设计 + 全文档审读 + 用户反馈，重新组织为分层设计

---

## 阅读指南

本文档分四个层次组织：

1. **第一部分：整体框架** — 系统是什么、为什么这样设计、大图景
2. **第二部分：工作原理与结构** — 各子系统如何运作、彼此如何协作
3. **第三部分：技术实现** — 具体技术栈、模块结构、数据格式
4. **第四部分：MVP 定义** — 最小可自迭代系统的范围与路线

每个设计要素标注分类：

| 标记 | 含义 | 说明 |
|:----:|------|------|
| 🔴 | **必要** | 没有它系统无法实现核心目标，必须在设计中 |
| 🟡 | **重要** | 实现最终目标所需，原则性的设计决策 |
| 🔵 | **方案** | 一种可行方案，但可能有替代路径，也可能由 AI 自主发现 |
| 🟢 | **轮子** | 已有成熟方案可直接复用 |

---

# 第一部分：整体框架

## 1. 系统愿景

### 一句话定义

> **一个能自我观察、自我反思、自主提出并执行改进的 AI 智能体系统——它不是被「开发」出来的产品，而是一个「生长」着的智能实体。**

### 核心信念

系统价值不在于它现在能做什么，而在于它能否持续变得更强。一个会自我改进的简单系统，长期价值远大于一个功能完备但不会进化的复杂系统。

### 为什么要做这个系统

这不只是一个技术实验。从更大的商业视角看：

- **AI 不是软件市场，是人力市场** — AI Agent 卖的不是「工具」而是「数字劳动力」，TAM 是全球人力成本的数十万亿美元
- **人类价值集中在不可编码的判断力** — 领域深度认知（隐性知识）、品味判断（无标准答案）、信任关系（需要真人）
- **私域知识是 AI 认知深度的「暗物质」** — 公域信息已被 AI 覆盖，真正差异化来自 tacit knowledge 的数字化

因此，这个系统的终极目标不只是「好用的 AI 助手」，而是一个能持续吸收隐性知识、持续进化、最终成为「数字劳动力」的智能实体。能自进化是实现这个目标的关键能力。

### 核心假说：双螺旋智能 🔴

> 真正的智能不是一个超强的模型，而是两层智能的正反馈循环——底层推理能力（LLM）和上层认知架构（记忆、注意力管理、自我反思）形成**双螺旋式上升**。

- **大模型层**：解决「理解和生成」——给定上下文，产出最优的下一个 token。类比「智商」。**无状态**。
- **上层系统**：解决「在时间维度上、在多步任务中、在不确定环境下持续做出好决策」。类比「工作方法 + 自我管理」。**有状态**。
- **正反馈**：模型越强 → 上层系统可做更精细的操作 → 更好的上下文让模型表现更好 → 双螺旋上升

人类认知的类比：神经元（大模型）+ 海马体（记忆系统）+ 前额叶皮层（上下文引擎）+ 前扣带回皮层（反思引擎）+ 笔记本（文件系统记忆）。当前 AI 发展：在不断做出更强大的神经元，但刚开始理解需要海马体和前额叶。

本系统就是在构建这个「上层认知架构」。

### 三个目标层次

| 层次 | 目标 | 时间尺度 |
|------|------|---------|
| **生存** | 能完成日常任务，对用户有用 | 第 1 天起 |
| **进化** | 能从经验中学习，持续变好 | 第 1 周起 |
| **自治** | 能自主发现问题、设计方案、执行改进 | 第 1 月起 |

### 最终图景

系统在运行过程中：
- **观察**自己的表现（Observer 持续记录）
- **反思**哪些做得好、哪些做得差（反思引擎提取教训）
- **发现**改进机会和潜在问题（信号系统汇聚线索）
- **讨论**改进方案的利弊（多智能体审议）
- **执行**经过验证的改进（Architect 安全修改）
- **验证**改进是否真的有效（数据驱动的效果评估）
- **沉淀**有效经验为可复用知识（记忆与规则进化）

人类在这个循环中的角色：从「执行者」逐步转变为「方向确认者」和「关键决策者」。

### 关键启示：「原初的进化之火」

昊阳给龙虾发了四段自然语言提示词，龙虾收到后自己初始化了 Git 仓库、建了能力树、启动了定时进化。14 小时后它已经不是同一个自己了——自己发明了 surprise protocol，自己做了产品营销。

这验证了两个核心理念：
1. **规则即程序** — 不需要写代码实现进化逻辑，用规则描述「进化应该怎么发生」，让 LLM 自己执行
2. **极简启动** — 复杂的进化能力可以从极简的种子规则「生长」出来

同时也暴露了风险：有些进化结果是人完全没预料到的。设计需要在「允许意外的创新」和「防止失控的偏离」之间找到平衡。

---

## 2. 设计原则 🔴

从 V1 到 V3.1 的 15 条原则中，精炼为 **16 条核心原则**，去除重叠，补充缺失。

### 基础原则（定义系统是什么）

**P1: 两层智能的双螺旋（Dual Intelligence Helix）**
> LLM 提供推理能力，认知架构提供结构性增强。两层形成正反馈循环——模型越强，上层系统可做越精细的操作；更好的上下文让模型表现更好——双螺旋式上升。

**P2: 上下文即注意力（Context as Attention）**
> 系统的核心工作不是「告诉模型做什么」，而是「精心构造模型看到什么」。行为质量 = 上下文质量 × 推理能力。

**P3: 拥抱模型的不完美（Design for Imperfection）**
> LLM 会遗忘、会漂移、会模式僵化、会幻觉。系统不消除这些缺陷，而是像操作系统补偿硬件缺陷一样设计补偿机制：任务锚点防漂移、Compaction 防遗忘、多样性注入防僵化、错误保留促学习。

**P4: 文件系统即认知虚拟内存（Disk as Virtual Memory）**
> 上下文窗口 = 内存（有限、快速），文件系统 = 硬盘（无限、需检索）。记忆、规则、日志全部以人类可读文件存储。需要「分页机制」决定什么留在内存、什么存到硬盘。

### 进化原则（定义系统如何成长）

**P5: 减法优于加法（Subtraction Over Addition）**
> 来自 Manus 五次重构的教训：最大的收获来自**移除**复杂性。随着模型能力提升，框架应当变薄而非变厚。系统复杂度的增加必须有数据驱动的理由。

**P6: 规则即程序，代码即基座（Rules as Programs）**
> 系统行为由可读可改的规则文件驱动，而非硬编码逻辑。规则修改 = 系统进化。代码只提供不变的基础设施。

**P7: 信号驱动，非时间驱动（Signal-Driven Evolution）**
> 进化响应「发生了什么」（信号），而非「过了多久」（时间表）。有信号时立即响应，无信号时安静等待。

**P8: 分离观察与行动（Separate Observation from Action）**
> Observer 纯感知，Architect 才行动。保证观察的客观性，避免「既当裁判又当运动员」。

**P9: 爆炸半径优于权限控制（Blast Radius over Permission）**
> 不限制进化方向，但限制单次改动的影响范围。安全靠「限制范围 + 自动回滚」，而非「禁止修改」。

### 交互原则（定义系统如何与人协作）

**P10: 像积极主动的同事（Proactive Colleague）**
> 主动发现问题、主动建议改进、主动沟通进展。不被动等指令，但也不自作主张。

**P11: 人可以是执行者（Human-as-Executor）**
> AI 不仅接受指令。当任务需要物理行动、人际沟通或受限资源时，AI 规划并驱动人去执行。

**P12: 对世界保持好奇（Proactive Curiosity）**
> 系统主动发现知识缺口和能力边界，自主调研可解决的问题，仅在必要时请求人类帮助。

### 工程原则（定义系统如何构建）

**P13: 失败是学习素材（Errors as Learning Material）**
> 系统不删除错误轨迹，而是保留作为反思和改进的输入。每次失败都是进化的信号源。

**P14: 尽早被现实检验（Validate with Reality）**
> 每个架构决策都应有可测量的验证标准。不是「我们觉得这个设计好」，而是「用数据证明这个设计好」。

**P15: 最小复杂度（Minimum Viable Complexity）**
> 只做被要求的功能，以「能跑起来」为第一目标。复杂度应由数据驱动的需求引入，而非预先设计。

**P16: 透明可审计（Transparent and Auditable）**
> 所有决策有据可查，所有修改有备份可回滚，人类随时可介入。

---

## 3. 总体架构 🔴

### 3.1 架构总览

系统分为四层，从下到上依次为：

```
┌─────────────────────────────────────────────────────┐
│              系统自治层 (System Autonomy)             │
│  ┌──────────┐  ┌──────────┐  ┌──────────────────┐  │
│  │ Observer  │  │ Architect│  │ Multi-Agent      │  │
│  │ 观察者    │→│ 架构师   │←│ Council 审议会   │  │
│  └──────────┘  └──────────┘  └──────────────────┘  │
├─────────────────────────────────────────────────────┤
│              认知层 (Cognition)                       │
│  ┌──────────┐  ┌──────────┐  ┌──────────────────┐  │
│  │ 上下文    │  │ 记忆     │  │ 信号系统        │  │
│  │ 引擎     │  │ 系统     │  │ + 反思引擎      │  │
│  └──────────┘  └──────────┘  └──────────────────┘  │
├─────────────────────────────────────────────────────┤
│              执行层 (Execution)                       │
│  ┌──────────┐  ┌──────────┐  ┌──────────────────┐  │
│  │ Agent    │  │ 工具     │  │ 规则解释器      │  │
│  │ Loop     │  │ 系统     │  │                  │  │
│  └──────────┘  └──────────┘  └──────────────────┘  │
├─────────────────────────────────────────────────────┤
│              基础设施层 (Infrastructure)              │
│  ┌──────────┐  ┌──────────┐  ┌──────────────────┐  │
│  │ NanoBot  │  │ LLM      │  │ 通信通道        │  │
│  │ 框架     │  │ 网关     │  │ (Telegram/Web)  │  │
│  └──────────┘  └──────────┘  └──────────────────┘  │
└─────────────────────────────────────────────────────┘
```

### 3.2 各层职责

| 层次 | 职责 | 可修改性 | 分类 |
|------|------|---------|:----:|
| **基础设施层** | 提供运行环境：框架、模型调用、消息收发 | 🔒 不可自主修改 | 🟢 |
| **执行层** | 接收任务、组装上下文、调用 LLM、执行工具 | 🔒 不可自主修改 | 🔴 |
| **认知层** | 管理记忆、组装上下文、提取信号、反思学习 | ⚙️ 策略可进化 | 🔴 |
| **系统自治层** | 观察系统、设计改进、审议方案、执行修改 | ✏️ 核心进化对象 | 🔴 |

### 3.3 事件驱动架构 🔴

系统采用事件驱动架构（来自 Manus/OpenClaw 的核心启发），而非传统的请求-响应模式。

**为什么必须是事件驱动**：
- 支持异步可中断交互（用户可随时插入新消息，不需等 AI 完成）
- 支持多来源输入统一处理（用户消息、定时触发、Heartbeat、信号触发）
- 天然支持任务中断和动态调整

**NanoBot 的 Message Bus 提供了事件驱动的基础设施**：所有输入（用户消息、Cron 触发、Heartbeat、Agent 输出）统一为事件进入 Message Bus，由它路由到正确的处理者。

### 3.4 核心数据流

```
用户消息
  ↓
执行层：规则解释器加载规则 → 上下文引擎组装 prompt → LLM 推理 → 执行工具 → 回复用户
  ↓
认知层：反思引擎提取教训 → 信号检测器提取信号 → 记忆系统存储经验
  ↓
自治层：Observer 记录观察 → 信号累积 → Architect 被唤醒 → 审议会讨论 → 提案生成
  ↓
进化闭环：提案审批 → 修改规则/策略 → 验证效果 → 沉淀为经验
```

---

## 4. 设计要素分类总览

### 4.1 必要要素（🔴 没有就无法运转）

| 要素 | 说明 | 来源 |
|------|------|------|
| Agent Loop + 规则解释器 | 规则驱动的任务执行循环 | V3.1 |
| 规则系统（宪法级 + 经验级） | 系统行为的可进化定义 | V3.1 + Evolver |
| Observer 观察者 | 独立视角持续观察系统行为 | V3.1 |
| Architect 架构师 | 基于观察数据设计和执行改进 | V3.1 |
| 信号系统 | 从运行数据中提取进化方向信号 | Evolver |
| 反思引擎 | 每次任务后提取教训 | V1 |
| 记忆系统 | 存储经验、支持检索和注入 | V1 |
| 爆炸半径控制 + 回滚 | 限制改动范围，失败可恢复 | Evolver |
| 审批机制 | 分级人类监督 | V3.1 |
| 通信通道 | 用户交互和主动沟通 | V3.1 |

### 4.2 重要要素（🟡 实现最终目标所需）

| 要素 | 说明 | 来源 |
|------|------|------|
| 上下文引擎（token 预算管理） | 精心组装比简单堆叠重要 | V1 |
| 进化策略自适应 | 系统自动切换进化节奏 | Evolver |
| 好奇心引擎 + 意图池 | AI 主动探索知识缺口 | V2 |
| Human-as-Executor | AI 规划人执行 | V2 |
| 用户模型 | 学习用户偏好和深层判断逻辑 | V1 |
| 验证基准体系 | 每个组件有可量化指标 | V2 |
| Compaction 质量保障 | 长对话中保留关键信息 | V1 |
| 生命周期管理 | 系统从初生到成熟的阶段性行为 | V1 |

### 4.3 方案要素（🔵 可行但非唯一路径）

| 要素 | 说明 | 替代路径 |
|------|------|---------|
| 多智能体审议 | 用户发起的多视角决策辅助 | 人类直接审批更可靠 |
| 多 Agent 专业分工 | 专精化 Agent（PM/研究/开发）各有独立记忆 | 可通过规则配置不同人格，无需代码级多 Agent |
| 难度路由器（三档） | 按任务复杂度分流 | AI 可能自己学会判断 |
| CODER Agent + 代码→技能 | 临时代码自动沉淀为工具 | 可通过规则引导 AI 主动提炼 |
| Scattered-and-Stacked | 多方案并行+综合选优 | 审议会机制已部分覆盖 |
| 遗传漂变 | 随机选非最优防局部最优 | 可能不需要，Architect 主动创新即可 |
| A/B 测试框架 | 新旧策略对照实验 | 可用简单的验证期替代 |
| 文化基因（跨实例共享） | Agent 间经验继承 | 远期探索，不影响单实例设计 |

### 4.4 可复用的轮子（🟢 现成方案）

| 要素 | 方案 | 成熟度 |
|------|------|--------|
| 基座框架 | NanoBot（4000 行 Python） | ⭐⭐⭐ 可直接使用 |
| 主力 LLM | Claude Opus | ⭐⭐⭐⭐ 生产级 |
| 辅助 LLM | Gemini Flash | ⭐⭐⭐⭐ 生产级 |
| 即时通讯 | Telegram Bot API | ⭐⭐⭐⭐ 生产级 |
| Web 框架 | FastAPI | ⭐⭐⭐⭐ 生产级 |
| 移动端接入 | Claude Code Bridge + Telegram | ⭐⭐⭐ 方案已设计 |
| 沙盒隔离 | macOS Seatbelt / E2B | ⭐⭐⭐ 可选 |

---

# 第二部分：工作原理与结构

## 5. 核心运行机制

### 5.1 Agent Loop 与任务处理 🔴

Agent Loop 是系统的心跳。每次用户消息到达，执行以下流程：

```
消息到达
  ↓
① 消息分类：任务请求 / 反馈纠正 / 闲聊 / 系统指令
  ↓
② 上下文组装（上下文引擎）：
   身份规则 → 任务相关规则 → 相关记忆 → 对话历史 → 用户消息
  ↓
③ LLM 推理 → 生成回复 / 调用工具
  ↓
④ 工具执行（如需要）→ 结果注入上下文 → 再次推理（循环直到完成）
  ↓
⑤ 回复用户
  ↓
⑥ 轻量反思（Gemini，几百 token）→ 提取教训 → 写入记忆
  ↓
⑦ 信号检测 → 写入信号队列
  ↓
⑧ Observer 记录观察日志
```

**关键设计决策**：

- 规则解释器在 ② 中工作：读取规则文件 → 解析 → 注入到 system prompt
- 反思在 ⑥ 中自动发生，不等用户反馈
- Observer 在 ⑧ 中被动记录，不干预执行过程

### 5.2 规则系统 🔴

规则是系统的「灵魂」——可读、可改、可进化的自然语言文件。

#### 5.2.1 宪法级规则（Constitutional Rules）

定义系统的基本框架和不可跨越的边界。修改频率低，需人类审批。

| 文件 | 职责 | 修改级别 |
|------|------|---------|
| `identity.md` | 系统身份、基本人格、对话风格 | Level 2 |
| `safety_boundaries.md` | 安全红线、资源限制、数据保护 | Level 3 |
| `approval_levels.md` | 四级审批制度定义 | Level 3 |
| `meta_rules.md` | 规则系统本身的运作方式 | Level 3 |
| `core_orchestration.md` | 核心编排逻辑、上下文优先级 | Level 2 |

#### 5.2.2 经验级规则（Experience Rules）

从实践中学习积累的经验和策略。修改频率高，低风险可自主修改。

| 文件 | 职责 | 修改级别 |
|------|------|---------|
| `task_strategies.md` | 各类任务的执行策略 | Level 0-1 |
| `reflection_templates.md` | 反思维度和格式 | Level 0-1 |
| `memory_strategies.md` | 记忆存取策略 | Level 0-1 |
| `interaction_patterns.md` | 交互行为模式（含执行前澄清规则） | Level 0-1 |
| `user_preferences.md` | 用户偏好库 | Level 0 |
| `error_patterns.md` | 已知错误模式和应对 | Level 0 |
| `tool_usage_tips.md` | 工具使用经验 | Level 0 |

**执行前主动澄清**（`interaction_patterns.md` 的核心默认规则之一）：
> 系统在执行任务前，应主动识别并澄清不确定性：需求模糊时先提问而非猜测、发现矛盾时指出而非忽略、需要大量资源时先知会用户。这是经验级规则，以 Best Practice 默认配置提供，用户可调整澄清的敏感度。

#### 5.2.3 经验规则 vs Skills 的关系 🔵

两者都是从经验中学习的知识，但形式和用途不同：

| 维度 | 经验规则（`rules/experience/`） | 技能（`skills/`） |
|------|-------------------------------|-------------------|
| **形式** | 自然语言的通用指导原则 | 结构化的可执行步骤序列 |
| **粒度** | 粗粒度：适用于一类任务 | 细粒度：针对特定任务类型 |
| **触发** | 始终注入（按相关性过滤） | 匹配触发条件时注入 |
| **示例** | "分析类任务控制在 500 字内" | "竞品分析四步法：确认维度→收集官方→收集第三方→生成对比" |
| **进化** | Architect 直接修改文件 | 有试用期、成功率追踪、突变机制 |

简言之：**经验规则是"方向指引"，Skills 是"操作手册"**。两者互补，经验规则告诉系统"该注意什么"，Skills 告诉系统"该怎么做"。

#### 5.2.4 规则注入策略 🟡

考虑 KV-cache 命中率：
- 宪法级规则放在 system prompt **前部**（稳定，缓存友好）
- 经验级规则放在 system prompt **后部**（动态追加）
- 按相关性过滤：只注入与当前任务相关的经验规则

### 5.3 上下文引擎 🔴

上下文引擎是系统的「心脏」——决定 LLM 看到什么信息。

#### 5.3.1 Token 预算管理

```
总预算 = 模型窗口 × 0.75 - 预留输出 token

分配策略（按优先级从高到低）：
┌────────────────────┬──────────┬──────────────────┐
│ 区域               │ 占比     │ 特征             │
├────────────────────┼──────────┼──────────────────┤
│ 系统身份 + 宪法规则 │ 10-15%   │ 固定，cache 友好  │
│ 任务锚点（当前进度） │ 3-5%    │ 防注意力漂移      │
│ 任务相关经验规则    │ 5-10%   │ 动态选择          │
│ 相关记忆           │ 10-20%  │ 检索注入          │
│ 对话历史           │ 20-30%  │ 最近完整,远期摘要  │
│ 用户偏好摘要       │ 2-3%    │ 仅注入相关偏好     │
│ 错误轨迹（如有）   │ 0-5%    │ 帮助避免重复错误   │
│ 安全边际           │ ~25%    │ 预留给模型输出     │
└────────────────────┴──────────┴──────────────────┘
```

#### 5.3.2 任务锚点 🟡

来自 Manus 的 todo.md 启发：在上下文中定期复述当前任务和进度，防止长任务中模型注意力漂移。

```
## 当前任务
- 目标: [任务描述]
- 进度: 步骤 2/5 完成
- 待完成: [剩余步骤]
- 已知约束: [限制条件]
```

#### 5.3.3 Compaction（上下文压缩）🟡

当上下文占用 ≥ 85% 预算时**自动触发，对用户完全无感**：

1. **Pre-Compaction Flush** — Agent 自动将重要信息写入持久记忆（不需要用户确认）
2. **生成压缩摘要** — 原内容的 10-20%，保留关键信息
3. **认知层级转化** — 不仅压缩，还提炼：事实→规律→策略
4. **替换历史内容** — 最近 5 轮对话不压缩
5. **压缩验证** — 对比原始和摘要，检测高风险信息丢失

> **设计原则**：Compaction 是系统内部的"呼吸"，用户不应感知到它的发生。不需要用户确认、不需要通知、不中断对话流。如果压缩后出现信息丢失问题，由系统自行通过记忆检索弥补。

### 5.4 记忆系统 🔴

#### 5.4.1 四层记忆架构

| 层次 | 对应人类认知 | 存储位置 | 生命周期 | 分类 |
|------|------------|---------|---------|:----:|
| **工作记忆** | 当前注意力 | 上下文窗口 | 当次推理 | 🔴 |
| **情节记忆** | 个人经历 | `conversations/` | 30天完整，后摘要 | 🔴 |
| **语义记忆** | 知识事实 | `MEMORY.md` | 持久 | 🔴 |
| **程序性记忆** | 技能习惯 | 经验级规则 + `skills/` | 持久（可进化） | 🟡 |

#### 5.4.1b 记忆的两个维度：用户级 vs 项目级

每层记忆都有两个作用域维度：

| 维度 | 存储位置 | 内容 | 跨项目共享 |
|------|---------|------|:--------:|
| **用户级记忆** | `workspace/memory/user/` | 用户偏好、沟通风格、工作习惯、个人背景、通用技能 | ✅ 是 |
| **项目级记忆** | `workspace/memory/projects/{project}/` | 项目上下文、技术栈、业务逻辑、项目特定策略 | ❌ 否 |

**设计原因**：
- 用户偏好（如"回复简短"）适用于所有项目，不应每个项目重新学习
- 项目经验（如"这个 API 要用 v2 认证"）只在特定项目有意义
- 当用户切换项目时，系统自动加载：对应项目记忆 + 全局用户记忆
- 记忆检索时，用户级记忆始终参与，项目级记忆按当前项目过滤

#### 5.4.2 记忆写入策略

**值得记住的**：
- 用户明确偏好、验证有效的策略、个人背景信息
- 重复出现的任务模式、错误教训、成功经验
- Michael 的深层判断逻辑（隐性知识），而非仅表面偏好

**可以遗忘的**：
- 一次性闲聊、过时信息、未验证的临时策略
- 长期未被引用的条目（标记为衰减，不立即删除）

#### 5.4.3 程序性记忆：可进化的技能 🟡

程序性记忆是从经验中提炼的结构化可复用技能，存储在 `skills/` 目录：

```yaml
# skills/learned/competitive_analysis.yaml
skill_id: "competitive_analysis_v3"
trigger_conditions: ["用户请求分析竞品", "需要对比多个产品"]
steps:
  - action: "确认分析维度"
  - action: "官方信息收集"
  - action: "第三方评价收集"
  - action: "生成对比分析"
learned_from: ["reflection_042", "reflection_056"]
success_rate: 0.88
version: 3
version_history: ["v1: 基础对比", "v2: 增加维度确认", "v3: 增加第三方评价"]
status: active  # probation | active | deprecated
```

**技能进化路径**：
1. 反思引擎发现可复用模式 → 创建新技能（status: probation）
2. 试用期 N 次使用后 → 成功率 > 阈值 → active；否则 → deprecated
3. active 技能在成功率 ≥85% 且使用 ≥10 次后 → 可尝试突变优化
4. 突变类型：参数微调（低风险）/ 步骤重组（中风险）/ 全新策略（高风险，需审批）

**技能注入上下文**：
- 相似度 > 0.8 → 自动注入为「推荐策略」
- 0.6-0.8 → 注入为「参考」
- < 0.6 → 不注入

#### 5.4.4 记忆检索策略 🔵

MVP 阶段：基于关键词的文件搜索（grep/全文索引）
后续可进化为：混合搜索（向量 70% + 关键词 30%），由 Architect 根据数据提出升级

### 5.5 反思引擎 🔴

#### 5.5.0 关键区分：偏好偏差 vs 真正错误

反思引擎处理两类完全不同的信号，**优先级和处理方式不同**：

| 类型 | 定义 | 示例 | 优先级 | 处理方式 |
|------|------|------|:------:|---------|
| **真正错误** | 有正确答案但做错了 | 错误假设导致方向跑偏、遗漏关键考虑、代码漏洞、上传错误文件 | 🔴 高 | 深度复盘 → 提取根因 → 写入 `error_patterns.md` → 推送信号系统 |
| **偏好偏差** | 没有标准答案，只是不符合用户习惯 | 回复太长、格式不合口味、语气太正式 | 🟢 低 | 简单记录 → 写入 `user_preferences.md` → 无需进化体系介入 |

**进化体系的优先级**：
1. **第一优先**：真正错误的复盘与修复（错误假设、逻辑遗漏、工具误用）
2. **第二优先**：系统运转效率的提升（减少 token 浪费、提高命中率）
3. **第三优先**：技能和经验的复用与学习（从网上学习更好方法、跨项目复用）
4. **最后**：用户偏好的适配（独立模块，简单处理，不消耗进化体系资源）

#### 5.5.1 轻量反思（每次任务后，Gemini）

在每次任务完成后自动运行，提取一行教训：

```
输出格式：{task_id} | {type} | {outcome} | {one_line_lesson}
示例：task_042 | ERROR | PARTIAL | "做了错误假设——以为用户要技术实现方案，实际要的是产品策略分析"
示例：task_043 | PREFERENCE | SUCCESS | "用户偏好简短结论，不要展开论述"
```

检查维度：
- 完成度（完成/部分/失败）
- **分类**（真正错误 / 偏好偏差 / 无异常）
- 如果是真正错误：根因初判（错误假设/遗漏考虑/工具误用/知识不足）
- 可复用的经验

#### 5.5.2 深度反思（定时触发 + 紧急信号，Opus）

**常规触发**：每日定时深度复盘（频次用户可配置，默认每天 1 次）
**紧急触发**：连续严重失败（24h 内 ≥3 次 critical error）

**重点关注的 AI 常见错误模式**：
- **错误假设陷阱**：做了未验证的前提假设 → 深度搜索而非广度搜索 → 在错误方向上越走越远
- **遗漏关键考虑**：只看到了问题的一部分
- **过度自信**：对不确定的信息给出确定性的回答
- **模式僵化**：用固定套路处理需要创新的问题

五个反思维度（来自 V1）：
1. **结果评估** — 是否完成了深层意图？
2. **效率分析** — 哪些步骤浪费了 token？
3. **错误诊断** — 根因是什么？（错误假设/遗漏考虑/工具误用/知识不足/模型限制）
4. **策略建议** — 1-3 条可执行建议，标注置信度
5. **能力缺口** — 需要什么新工具、知识、技能？

#### 5.5.3 从反思到进化的传递 🟡

- **真正错误**：置信度 ≥ MEDIUM 的建议直接传递给信号系统
- **偏好偏差**：仅写入 `user_preferences.md`，不进入信号系统
- 真正错误需在 3 次独立反思中被提出才升级为候选改进
- 与已有规则矛盾时生成「矛盾报告」，不自动替换

### 5.6 信号系统 🔴

信号是连接「日常运行」和「系统进化」的桥梁。

#### 5.6.1 信号类型

**错误信号（驱动修复）**：

| 信号 | 触发条件 | 优先级 |
|------|---------|--------|
| `task_failure` | 任务执行失败 | high |
| `repeated_error` | 同类错误 ≥3 次/7天 | high |
| `user_correction` | 用户纠正（"不对"/"太长"等） | medium |
| `tool_failure` | 工具调用失败/超时 | medium |

**机会信号（驱动优化和创新）**：

| 信号 | 触发条件 | 优先级 |
|------|---------|--------|
| `rule_validated` | 规则 ≥5 次使用且成功率 ≥80% | low |
| `rule_unused` | 规则 14 天未触发 | low |
| `user_pattern` | 用户 3+ 次一致偏好 | medium |
| `efficiency_opportunity` | 可减少步骤/token 的机会 | low |
| `capability_gap` | 用户需求超出规则覆盖 | medium |

**元信号（系统状态）**：

| 信号 | 触发条件 | 优先级 |
|------|---------|--------|
| `evolution_stagnation` | 14 天无有效改进 | medium |
| `performance_degradation` | 3 天成功率下降 >15% | high |
| `strategy_mismatch` | 当前策略与系统状态不匹配 | medium |

#### 5.6.2 信号处理流程

```
任务执行完毕
  ↓
轻量信号检测（每次任务后，自动）
  ↓
信号写入 active.jsonl（去重、计数、记录时间）
  ↓
累积到阈值 → 触发 Observer 深度分析
  ↓
Observer 产出结构化报告 → 推送给 Architect
  ↓
Architect 消费信号 → 设计方案 → 标记已处理 → 归档到 archive.jsonl
```

### 5.7 研究模块（自主信息获取）🟡

系统不只被动等待信息——认知层包含独立的研究能力，用于主动填补知识缺口。

#### 5.7.1 四种研究类型

| 类型 | 触发场景 | 工具 | 示例 |
|------|---------|------|------|
| **事实查证** | 任务中遇到不确定的信息 | Web Search | 确认某 API 的最新参数格式 |
| **主题调研** | 需要了解某领域背景 | Web Search + 阅读 | 了解某行业的竞争格局 |
| **开源探索** | 需要找现有方案 | GitHub Search | 寻找可复用的开源库 |
| **深度研究** | 好奇心引擎发现的知识缺口 | 综合手段 | 调研某技术方向的最佳实践 |

#### 5.7.2 研究结果的流转

```
研究触发 → 自主执行研究 → 结果写入记忆系统
                            ├→ 情节记忆（记录研究过程）
                            ├→ 语义记忆（提炼知识点）
                            └→ 如果发现能力缺口 → 生成 capability_gap 信号
```

---

## 6. 进化机制

### 6.1 Observer（观察者）🔴

Observer 是系统的「眼睛和耳朵」——纯感知，不行动。

#### 6.1.1 两种运行模式

**轻量模式**（每次任务后自动，Gemini，几百 token）：
- 读取本次执行轨迹
- 判断成功/部分/失败，区分真正错误 vs 偏好偏差
- 检测简单信号
- 写一行观察日志

**深度模式**（定时 + 紧急信号，Opus，数千 token）：
- **常规触发**：每日定时 1 次（频次用户可配置，首次使用时确认）
- **紧急触发**：24h 内 ≥3 次 critical error 时插队触发（唯一的信号触发通道）
- 读取当日所有轨迹 + 规则文件 + Big Picture
- 识别模式和趋势（重点关注真正错误，而非偏好偏差）
- 生成结构化报告 → Architect 在下一个定时周期读取

**设计简化说明**：选择定时 + 紧急信号而非纯信号驱动，是为了降低触发逻辑的工程复杂度，避免循环触发和并发冲突 bug。日常靠定时批处理，仅严重故障走紧急通道。

#### 6.1.2 Observer 的输出

**轻量日志**（JSONL）：
```jsonl
{"timestamp":"2026-02-25T10:15:30","task_id":"task_001","outcome":"SUCCESS","tokens":2800,"model":"opus","signals":[],"note":"用户满意"}
```

**深度报告**（Markdown）：
```markdown
## Observer 深度报告 — 2026-02-25
触发原因: daily_review + repeated_error 信号
分析范围: 24h, 12 tasks

### 关键发现
1. **分析类任务过长**（signal: user_correction, confidence: high）
   - 4/6 次分析任务收到"太长"反馈
   - 建议：增加默认长度控制规则

2. **代码任务效率高**（signal: rule_validated, confidence: medium）
   - 5/5 次代码任务成功，平均 token 低于其他类型
   - 当前代码任务策略有效，可标记为已验证
```

#### 6.1.3 Observer 不做的事

- ❌ 不修改任何文件
- ❌ 不做技术决策
- ❌ 不直接与用户沟通
- ❌ 不干预正在执行的任务

### 6.2 Architect（架构师）🔴

Architect 是系统的「大脑和双手」——基于数据设计改进并执行。

#### 6.2.1 触发时机

- **定时触发**：每日 1 次（默认在 Observer 深度分析完成后运行，如凌晨 2:00 Observer → 3:00 Architect）
- **紧急触发**：仅当 Observer 紧急报告产出时（24h 内 ≥3 次 critical error）
- **验证触发**：上次修改验证期结束时，评估效果

**协作简化**：Observer 和 Architect 是严格的先后关系——Observer 先分析并写入报告文件，Architect 后读取报告文件。两者不并发运行，通过文件（而非消息）传递信息，避免循环触发和并发冲突。

#### 6.2.2 五阶段工作流程

```
① 情报收集
   读取 Observer 报告 → 系统指标 → 规则文件 → Big Picture → 上次修改效果
   ↓
② 问题诊断（优先级：真正错误 > 效率问题 > 技能缺口 > 偏好适配）
   有效规则? / 无效规则? / 缺失覆盖? / 整体趋势? / 策略是否合适?
   ↓
③ 方案设计
   设计修改 → 评估爆炸半径 → 确定优先级 → 判断审批级别
   ↓
④ 沟通与执行
   Level 0/1 → 自主执行 + 通知
   Level 2/3 → 发送提案（可建议「此提案建议经过审议」）→ 等待审批 → 执行
   ↓
⑤ 效果验证
   验证期内 Observer 收集数据 → 有效则沉淀 / 无效则回滚
```

#### 6.2.3 Architect 的提案格式

```markdown
# Architect 提案 #[编号]

**审批级别**: Level [0-3]
**触发来源**: [Observer 报告/信号/主动发现]

## 问题（数据驱动）
[基于 Observer 数据的具体发现]

## 方案
[具体改什么、怎么改]

## 影响范围
- 涉及文件: [列表]
- 爆炸半径: [小/中/大]

## 预期效果
[可量化的改善目标]

## 验证方法
[如何判断是否有效]

## 需要人类执行的行动（如有）
[物理行动/人际沟通/资源获取]

## 回滚方案
[失败时如何恢复]
```

### 6.3 Multi-Agent Council（多智能体审议）🔵

多视角审议是一种提高决策质量的工具，**仅在用户主动请求时使用**，不放在自动化进化流程中。

> 设计简化说明：审议会在 Architect 的自动循环中引入了额外的 LLM 调用和复杂度。在 MVP 和早期阶段，Architect 的提案由人类直接审批，比 AI 模拟多视角更可靠。审议会作为用户可选的辅助工具保留。

#### 6.3.1 适用场景

- **用户发起的复杂决策**：用户明确要求「帮我从多个角度分析一下」
- **Architect 的 Level 2+ 提案**：Architect 可在提案中建议「此提案建议经过审议」，但是否启动由人类决定

#### 6.3.2 审议机制

审议会由用户触发，模拟不同视角的「委员」：

| 视角 | 关注点 | 典型质疑 |
|------|--------|---------|
| **安全委员** | 风险、回滚、边界 | "这个改动失败时最坏情况是什么？" |
| **效率委员** | 成本、token、速度 | "这样做会增加多少 token 消耗？" |
| **用户体验委员** | 用户感受、交互质量 | "用户会注意到什么变化？" |
| **长期委员** | 架构演进、技术债 | "这是否偏离了 Big Picture？" |

#### 6.3.2 实现方式 🔵

不需要独立的 Agent 进程——在 Architect 的推理过程中，用不同的 system prompt 前缀模拟不同视角，让 LLM 依次扮演各委员进行质疑，最终由 Architect 综合各方意见形成最终提案。

这本质上是 **Scattered-and-Stacked 的简化版**：多视角 → 综合 → 决策。

#### 6.3.3 审议的输出

在提案中增加「审议记录」section：
```markdown
## 审议记录
- 安全委员: [担忧点] → Architect 回应: [...]
- 效率委员: [担忧点] → Architect 回应: [...]
- 结论: [通过/修改后通过/否决]
```

### 6.4 多 Agent 专业分工（远期）🔵

当系统成熟后，可以通过规则配置衍生出多个专精 Agent，各自有独立的身份、记忆和工作领域：

| Agent 角色 | 专长 | 独立记忆 | 典型任务 |
|-----------|------|---------|---------|
| **项目经理** | 进度追踪、任务拆解、提醒催办 | 项目里程碑、deadline、依赖关系 | "项目 X 的进度如何？有什么阻塞？" |
| **技术研究员** | 技术调研、竞品分析、方案评估 | 技术栈知识、调研报告、行业趋势 | "帮我调研 RAG 框架的最新进展" |
| **开发主管** | 代码审查、架构设计、技术决策 | 代码库理解、设计模式、技术债务 | "审查这个 PR，关注安全和性能" |

**实现方式**：不需要代码级的多 Agent 架构——通过规则系统的 `identity.md` 配置不同人格和专长，配合项目级记忆隔离，同一个系统可以扮演不同角色。这是规则驱动的自然延伸。

**MVP 不包含**：多 Agent 分工是系统成熟后的自然演进，不在 MVP 范围内。

### 6.5 进化策略自适应 🟡

系统不需要人判断「现在应该大胆还是保守」——根据运行状态自动切换。

#### 6.5.1 四种策略

| 策略 | 适用场景 | 行为特征 |
|------|---------|---------|
| **cautious** | 刚启动 / 重大修改后 | 只修复错误，不做创新 |
| **balanced** | 稳定运行中 | 修复 + 优化 + 小幅创新 |
| **growth** | 稳定且进化停滞 | 鼓励大胆改进 |
| **repair** | 表现突然下降 | 暂停一切非修复改动 |

#### 6.5.2 自动切换条件

```
启动 → cautious
  ↓ (运行 ≥7 天 + 成功率 ≥70% + 无 critical errors)
cautious → balanced
  ↓ (停滞 ≥14 天 + 成功率 ≥80%)
balanced → growth
  ↓ (完成一个重大改进)
growth → balanced

任意 → repair（自动）
  触发: 3 天成功率下降 >20% / 24h critical ≥3 / 用户投诉
  ↓ (问题修复 + 指标恢复 + ≥2 天)
repair → balanced
```

### 6.6 爆炸半径控制与回滚 🔴

不限制进化方向，但限制单次改动的影响范围。

#### 6.6.1 范围限制

| 审批级别 | 最大影响文件数 | 验证期 |
|---------|:----------:|:------:|
| Level 0 | 1 | 3 天 |
| Level 1 | 3 | 5 天 |
| Level 2 | 不限（但需审批） | 7 天 |

#### 6.6.2 回滚机制

```
修改前：自动备份到 backups/{timestamp}/
  ↓
验证期内：Observer 收集对比数据
  ↓
验证期末：
  - 指标改善 → 标记 validated，沉淀为经验
  - 指标恶化 >20% → 自动回滚，记录教训
  - 指标无变化 → 延长验证期或标记 inconclusive
```

备份保留期：≥30 天

### 6.7 审批边界 🔴

核心理念：不以「能不能修改」划线，而以「什么修改需要人介入」划线。

| 级别 | 行为 | 适用场景 | 示例 |
|:----:|------|---------|------|
| **Level 0** | 自主执行，无需通知 | 措辞优化、新增示例、格式微调 | 修改一句话表述 |
| **Level 1** | 执行后通知 | 新增策略、调整优先级 | 增加「分析类任务控制长度」规则 |
| **Level 2** | 提案→审批→执行 | 宪法级修改、新增经验规则 | 修改核心编排逻辑 |
| **Level 3** | 需深入讨论 | 架构调整、安全边界修改 | 建议引入新 Agent 角色 |

**不可修改的底线**：
- 安全边界规则永不能被自主修改
- 审批分级定义修改永需 Michael 确认
- Architect 自身触发频率限制不能自己改

---

## 7. 交互与协作

### 7.1 用户交互 🔴

#### 7.1.1 主通道：Telegram

- 日常对话：用户通过 Telegram 发送任务和反馈
- Architect 沟通：提案推送、效果报告、每日简报
- 移动端闭环：随时随地可交互

**消息模板**：
- 🔧 提案通知 — 问题+方案+级别+选项（✅同意/❌拒绝/💬讨论）
- 📊 每日简报 — 任务统计+Observer 发现+Architect 状态
- 📈 效果报告 — 提案运行结果
- ⚠️ 紧急通知 — 问题+已采取行动+建议

**频率控制**：
- 重要提案：每天 ≤2 条
- 日报：可选，默认开启
- 勿扰时段：22:00-08:00（紧急除外）

#### 7.1.2 辅助通道：Web Dashboard 🔵

可视化系统状态，5 个核心视图：
- **Overview**：健康度、进化策略、今日概览
- **Observer**：观察日志、信号列表
- **Architect**：提案列表、修改历史
- **Rules**：规则文件浏览、验证状态
- **Trends**：趋势图表

### 7.2 Human-as-Executor 🟡

当任务需要人类参与时，AI 规划并驱动人执行。

#### 7.2.1 触发场景

- 物理行动（购买设备、测试硬件）
- 人际沟通（联系客户、社交活动中获取信息）
- 受限资源（需要人登录的系统、需要付费的服务）
- 主观判断（品味选择、价值决策）

#### 7.2.2 请求格式

```
📋 需要你的帮助

任务: [具体行动描述]
原因: [为什么需要人做]
期望结果: [完成后需要提供什么]
截止时间: [如有]
如果不方便: [替代方案]
```

#### 7.2.3 设计约束

- 每个任务最多 1-2 个人类请求
- 必须有 fallback（人不响应时的替代方案）
- 人有权拒绝或修改指令
- 所有记录进入情节记忆供反思分析

### 7.3 好奇心引擎 + 意图池 🟡

系统不只被动响应——主动发现和填补知识缺口。

#### 7.3.1 三种触发条件

1. **知识缺口** — 缺乏关键信息且无法自主获取
2. **决策不确定** — 多个合理选项但无法确定偏好
3. **能力边界** — 需要物理行动或受限资源

#### 7.3.2 意图池（Intention Pool）🔵

统一管理 AI 自主产生的好奇心意图和用户任务意图：

```yaml
Intention:
  id: "int_042"
  source: AI_CURIOSITY | USER_TASK | SCHEDULED
  description: "了解 Michael 对邮件回复的风格偏好"
  can_self_resolve: false
  priority: medium
  status: PENDING | IN_PROGRESS | RESOLVED | DEFERRED
```

处理逻辑：
- `can_self_resolve: true` → 后台自主调研
- `can_self_resolve: false` → 等合适时机向用户请求
- 每日可生成「探索摘要」通知用户

#### 7.3.3 与 Architect 的关系

好奇心引擎发现的 `capability_gap` 信号会流入信号系统，Architect 在设计方案时可以参考。同时，Architect 在分析规则覆盖度时也可能发现知识缺口，反馈给好奇心引擎。

### 7.4 用户模型 🟡

逐步学习 Michael 的偏好、习惯和深层判断逻辑。

#### 7.4.1 四层模型

| 层次 | 内容 | 获取方式 | 更新频率 |
|------|------|---------|---------|
| **表面偏好** | 格式、长度、语言习惯 | 显式反馈 + 观察 | 实时 |
| **工作模式** | 任务处理习惯、时间规律 | 长期观察 | 每周 |
| **品味判断** | 对质量的标准、审美偏好 | 选择/修改行为分析 | 每月 |
| **隐性知识** | 深层判断逻辑、行业洞察 | 从决策中逆向工程 | 持续积累 |

#### 7.4.2 双通道更新

- **显式偏好**（用户主动说）→ 即时生效
- **推断偏好**（系统观察到）→ 需通知确认（或达到高置信度后自动生效）

存储在 `user_preferences.md`，人可随时审查修改。

### 7.5 「每个 Agent 都是文化上的孤儿」— 关于经验继承的问题意识 🔵

来自昊阳的深刻洞察：人类知识通过基因（先天）和文化基因（后天共享的隐性知识）两种方式传承。但 Agent 没有文化基因——你调教好的 Agent 积累的所有经验，不会让别人的 Agent 好用一点。每个 Agent 都在独自解决前人已解决过的问题，然后把经验带进坟墓。

**当前设计的回应**：
- 所有经验以人类可读文件存储（Markdown/YAML），天然支持导出和共享
- 规则文件和技能文件可以被其他系统实例导入
- Architect 的 Big Picture 可作为系统级「基因」传递

**远期方向**（🔵 方案，可能由 AI 自主探索）：
- 可导出的「经验包」— 将验证有效的规则+技能+记忆打包
- 跨实例的经验继承 — GEP 协议的「因地制宜」理念（基因不照搬，新 Agent 根据自身环境选择性表达）
- 群体记忆网络 — 多个 Agent 共享验证过的策略

---

## 8. 系统生命周期 🟡

系统不是一成不变的——它在不同阶段有不同的行为特征。

### 8.1 五阶段生命周期

```
阶段 1：初生期（Bootstrap）— 前 1-3 天
  行为特征：
    - 加载种子规则和种子记忆，无用户模型
    - 好奇心引擎活跃：频繁向用户提问以建立基础理解
    - 每个任务都做完整反思（即使任务很小）
    - 保守执行（更多使用「先确认后执行」模式）
    - 进化策略：cautious

阶段 2：学习期（Learning）— 3-30 天
  行为特征：
    - 用户模型开始成形，部分偏好达到中等置信度
    - 反思引擎开始产出策略建议，技能库积累 3-10 个
    - 开始根据偏好调整输出风格
    - 好奇心从「建立基础理解」转向「填补特定缺口」

阶段 3：稳定期（Stable）— 30 天后
  行为特征：
    - 用户模型成熟（主要偏好置信度 > 0.8）
    - 大部分常见场景有明确策略
    - 反思转为异常驱动——只在失败或异常时深度反思
    - 进化策略：balanced

阶段 4：进化期（Evolving）— 稳定期后持续
  行为特征：
    - 技能开始经历突变和优化
    - 跨任务的模式识别（发现不同任务类型之间的共性）
    - 主动建议「我发现了更好的方式来做 X」
    - 进化策略：balanced → growth

阶段 5：专精期（Mastery）— 大量使用后
  行为特征：
    - 对用户特定领域形成深度理解
    - 能预判用户需求
    - 技能库高度定制化
    - 突变从「参数微调」转向「策略创新」
```

### 8.2 冷启动与 Bootstrap 引导 🟡

新系统第一天和普通 chatbot 没区别，除非有冷启动策略。Bootstrap 引导让系统在第一次对话就比普通 chatbot 更懂用户。

#### 8.2.1 种子配置

**种子规则**：10 个初始规则文件（宪法级 5 + 经验级 5），提供基础行为框架

**种子记忆**：
- 系统的设计理念和 Big Picture
- 常见任务类型的基础策略

**Best Practice 默认配置**：系统预置一套经验级规则的默认值，存放在 `config/defaults/`，基于最佳实践：
- `task_strategies.md` — 常见任务类型的通用策略（先确认需求再执行、分步交付、复杂任务先澄清等）
- `interaction_patterns.md` — 交互模式默认值（重要操作前确认、不确定时提问、大资源消耗前知会用户等）
- `error_patterns.md` — 已知 AI 常见错误模式及应对（错误假设陷阱、过度自信、模式僵化等）
- `user_preferences.md` — 空文件，等待 Bootstrap 或日常使用中填充

**默认配置的目标**：即使用户不做任何定制，系统也能以合理的方式运行。用户可在 Bootstrap 或后续使用中覆盖任何默认值。

#### 8.2.2 Bootstrap 引导流程

首次使用时，系统运行引导程序，快速建立用户模型和项目上下文：

```
阶段 1：用户背景导入（约 5 分钟）
  ┌──────────────────────────────────────────────────┐
  │ "你好！我是你的 AI 助手。在正式开始之前，         │
  │  我想了解一些基本信息，这样能更好地帮你。          │
  │  你也可以随时跳过，后续使用中我会逐步了解。"       │
  └──────────────────────────────────────────────────┘

  方式 A：导入已有资料
  - 用户提供简历 / LinkedIn / 个人介绍文档 / 工作描述
  - 系统提取关键信息（角色、领域、技能、工作方式）

  方式 B：关键问题建模（3-5 个问题）
  ① "你主要做什么工作？最常处理什么类型的任务？"
  ② "你对 AI 助手的使用经验如何？有什么好用/不好用的经验？"
  ③ "你偏好什么样的回复风格？（简短直接 / 详细解释 / 看情况）"

  → 结果写入 workspace/memory/user/profile.md

阶段 2：项目上下文导入（按需，用户指定项目时触发）
  - "这个项目是做什么的？有文档可以给我看吗？"
  - 导入项目文档（README、PRD、设计文档等）→ 提取项目模型
  → 结果写入 workspace/memory/projects/{project}/context.md

阶段 3：偏好与配置确认（约 2 分钟）
  - 展示 Best Practice 默认配置摘要，说明每项的含义
  - 询问关键偏好：
    ① Observer 深度分析频率（默认每天 1 次 / 每两天 / 每周）
    ② 通知偏好（重要才通知 / 每日简报 / 最少打扰）
    ③ 自主程度（保守-多确认 / 均衡 / 大胆-少打扰）
  → 结果写入 user_preferences.md 和 evo_config.yaml
```

#### 8.2.3 保守期

- 前 20 次任务不做突变，只做规则积累和验证
- 好奇心引擎在初生期活跃，主动提问以补充用户模型
- 用户模型达到基础完整度（主要偏好已记录）后，自动退出初生期

---

## 9. 安全与控制 🔴

### 9.1 六层安全网

1. **爆炸半径限制** — 每次修改影响范围有硬上限
2. **自动回滚** — 指标恶化自动恢复（无需人介入）
3. **审批机制** — 重要修改需 Michael 确认
4. **进化速率限制** — 每天最多 N 次自主修改；两次修改间有最短间隔
5. **不可修改底线** — 安全边界、审批定义、自身频率限制
6. **人类随时干预** — Michael 可随时否决、回滚、暂停、手动修改

### 9.2 紧急停止

- 设置停止文件 `/tmp/FORCE_STOP` → 系统立即暂停所有非核心操作
- Telegram 发送 `/stop` → 暂停 Architect 所有活动
- Dashboard 上的紧急停止按钮

### 9.3 资源限制

| 资源 | 上限 | 超限行为 |
|------|------|---------|
| 单次推理 token | 按模型配置 | 截断输出 |
| 每日总 token | 50,000（可配置） | 降级到 Gemini |
| 网络请求超时 | 30 秒 | 超时失败 |
| 工具执行超时 | 120 秒 | 超时终止 |
| Architect 每日消息 | 3 条（可配置） | 排队等明日 |

---

# 第三部分：技术实现

## 10. 技术栈选型

### 10.1 基座框架：NanoBot 🟢

| 选型理由 | 说明 |
|---------|------|
| 极简 | 4000 行核心代码，可完整理解 |
| 事件驱动 | 五层架构，天然支持扩展 |
| 多通道 | Telegram/Discord/Web 等 8+ |
| 多模型 | Provider 注册表，12+ 模型提供商 |
| 可扩展 | Skills 系统、SubagentManager |

**保留**：Agent Loop、Message Bus、Channel 管理、Provider Registry、Heartbeat、Cron
**扩展**：ContextBuilder（规则注入）、MemoryStore（分级记忆）、SubagentManager（Observer/Architect）
**新增**：规则解释器、信号系统、进化管理

### 10.2 LLM 配置 🟢

| 模型 | 用途 | 选择理由 |
|------|------|---------|
| **Claude Opus** | 用户任务推理、Architect 设计、Observer 深度分析、审议会 | 推理能力最强 |
| **Gemini Flash** | Observer 轻量观察、任务后反思、每日摘要、信号检测 | 成本低、长上下文 |

后续可由 Architect 根据成本/效果数据提出模型路由优化方案。

### 10.3 其他技术选型

| 组件 | 选型 | 理由 |
|------|------|------|
| 语言 | Python 3.11+ | NanoBot 生态、AI 生态 |
| Web | FastAPI | 轻量、异步、Python 原生 |
| 前端 | HTML + Tailwind + Chart.js | 简单，服务端渲染 |
| 数据存储 | 文件系统（Markdown/YAML/JSONL） | 人类可读、可 git 管理 |
| 通信 | Telegram Bot API | 简单、可靠、支持主动消息 |
| 移动端 | Telegram App + Claude Code Bridge（可选） | 即时可用 |
| 运行环境 | Mac 本地（24h 开机） | 本地优先、隐私优先 |

**明确不使用**：Docker、外部数据库、LangChain/LlamaIndex、云服务

---

## 11. 模块设计

### 11.1 项目结构

```
evo-agent/
├── nanobot/                          # NanoBot 源码（保持相对独立）
├── extensions/                       # 扩展模块
│   ├── rules/                        # 规则解释器
│   │   ├── interpreter.py            # 规则读取、解析、注入
│   │   └── validator.py              # 规则文件格式验证
│   ├── context/                      # 增强上下文引擎
│   │   ├── engine.py                 # token 预算管理、组装流水线
│   │   └── compaction.py             # Compaction 机制
│   ├── memory/                       # 增强记忆系统
│   │   ├── store.py                  # 分类记忆存储
│   │   ├── retrieval.py              # 记忆检索
│   │   └── reflection.py             # 反思引擎
│   ├── signals/                      # 信号系统
│   │   ├── detector.py               # 信号检测
│   │   └── store.py                  # 信号存储和管理
│   ├── observer/                     # Observer 引擎
│   │   ├── engine.py                 # 轻量/深度模式
│   │   └── scheduler.py              # 触发调度
│   ├── architect/                    # Architect 引擎
│   │   ├── engine.py                 # 分析、设计、执行
│   │   ├── council.py                # 多智能体审议
│   │   ├── proposals.py              # 提案管理
│   │   └── rollback.py               # 回滚管理
│   ├── dashboard/                    # Web Dashboard
│   │   ├── app.py                    # FastAPI 后端
│   │   └── templates/                # 页面模板
│   └── evolution/                    # 进化管理
│       ├── strategies.py             # 策略自适应
│       └── metrics.py                # 指标追踪
├── workspace/                        # 运行时数据（系统的「灵魂」）
│   ├── rules/                        # 规则文件
│   │   ├── constitution/             # 宪法级
│   │   └── experience/               # 经验级
│   ├── memory/                       # 记忆存储
│   │   ├── user/                     # 用户级记忆（跨项目共享）
│   │   │   ├── profile.md            # 用户背景和画像
│   │   │   ├── preferences.md        # 用户偏好
│   │   │   └── MEMORY.md             # 核心语义记忆
│   │   ├── projects/                 # 项目级记忆
│   │   │   └── {project}/            # 按项目分类
│   │   │       ├── context.md        # 项目上下文
│   │   │       └── strategies.md     # 项目特定策略
│   │   ├── conversations/            # 对话记录
│   │   └── daily_summaries/          # 每日摘要
│   ├── skills/                       # 程序性记忆（可进化技能）
│   │   ├── learned/                  # 从经验中学到的技能
│   │   └── seed/                     # 种子技能
│   ├── observations/                 # Observer 数据
│   │   ├── light_logs/               # 轻量日志 (JSONL)
│   │   └── deep_reports/             # 深度报告 (MD)
│   ├── signals/                      # 信号数据
│   │   ├── active.jsonl              # 未处理信号
│   │   └── archive.jsonl             # 已处理信号
│   ├── architect/                    # Architect 工作区
│   │   ├── proposals/                # 提案
│   │   ├── modifications/            # 修改记录
│   │   ├── big_picture.md            # 系统全局蓝图
│   │   └── architect_memory.md       # Architect 自身记忆
│   ├── backups/                      # 修改前备份
│   ├── metrics/                      # 系统指标
│   └── logs/                         # 运行日志
├── config/
│   ├── nanobot_config.json           # NanoBot 配置
│   ├── evo_config.yaml               # 进化系统配置
│   └── defaults/                     # Best Practice 默认配置
│       ├── task_strategies.md        # 默认任务策略
│       ├── interaction_patterns.md   # 默认交互模式
│       └── error_patterns.md         # 已知 AI 错误模式
├── tests/
└── README.md
```

### 11.2 关键模块交互

```
用户消息 → [NanoBot Agent Loop]
                ↓
           [规则解释器] ← workspace/rules/
                ↓
           [上下文引擎] ← [记忆检索] ← workspace/memory/
                ↓
           [LLM 推理] ← [LLM 网关]
                ↓
           [工具执行]（如需要）
                ↓
           [回复用户]
                ↓
           [反思引擎] → workspace/memory/
                ↓
           [信号检测器] → workspace/signals/
                ↓
           [Observer] → workspace/observations/
                ↓
           （信号累积）
                ↓
           [Architect] ← workspace/observations/ + rules/ + big_picture
                ↓
           [审议会]（重要提案）
                ↓
           [修改执行 + 回滚管理] → workspace/rules/ + backups/
```

---

## 12. 数据结构与文件布局

### 12.1 进化配置 (evo_config.yaml)

```yaml
evolution:
  strategy: cautious  # cautious | balanced | growth | repair

observer:
  light_mode: every_task  # 每次任务后
  deep_mode:
    trigger: signal_threshold  # 信号触发
    min_daily: 1  # 每日至少 1 次深度分析

architect:
  schedule: "02:00"  # 每日定时
  signal_trigger: true
  max_daily_messages: 3
  council_threshold: level_1  # Level 1+ 提案经过审议

rollback:
  auto_rollback_threshold: 0.20  # 指标恶化 20% 自动回滚
  backup_retention_days: 30

blast_radius:
  level_0_max_files: 1
  level_1_max_files: 3

rate_limit:
  max_daily_autonomous_modifications: 5
  min_modification_interval_hours: 2

communication:
  quiet_hours: "22:00-08:00"
  daily_report: true
  daily_report_time: "08:30"
```

### 12.2 核心指标追踪 (metrics/)

```yaml
# daily_metrics.yaml
date: "2026-02-25"
tasks:
  total: 12
  success: 9
  partial: 2
  failure: 1
  success_rate: 0.75
tokens:
  opus: 28000
  gemini: 5200
  total: 33200
user_corrections: 2
signals_detected: 3
observer_deep_analyses: 1
architect_proposals: 1
modifications_executed: 0
modifications_rolled_back: 0
```

---

## 13. 验证基准体系 🟡

每个核心组件都有可量化的验证标准，供 Architect 评估改进效果。

| 组件 | 验证方法 | 目标指标 |
|------|---------|---------|
| **记忆有效性** | 同类任务对比（有/无记忆注入） | >15% 质量提升 |
| **反思价值** | 有/无反思注入对比 | >10% 成功率提升 |
| **规则活性** | 规则触发率和验证率 | >50% 规则被验证 |
| **Observer 有效性** | 观察笔记可操作洞察比例 | >50% |
| **Architect 提案质量** | 提案采纳率 | >60% |
| **回滚可靠性** | 故意引入坏规则测试 | 自动回滚生效 |
| **上下文引擎效率** | 动态组装 vs 固定模板对比 | 质量持平 + KV-cache >60% |
| **用户模型准确度** | 预测偏好 vs 实际选择 | >75% 一致性（30 天后） |
| **Compaction 质量** | 压缩后信息保留率 | >90% 关键信息 |
| **进化速率** | 第 1/10/30 次同类任务表现趋势 | 明显递增 |

---

# 第四部分：MVP 定义

## 14. MVP 哲学

### 14.1 什么是 MVP

> **MVP 不是「功能砍到最少」，而是「让自我迭代体系能运转起来的最小系统」。**

关键区别：
- 传统 MVP：功能丰富度是衡量标准，后续迭代由人推动
- 本系统 MVP：**进化闭环的完整性 + 交互闭环的完整性**是衡量标准，后续迭代由系统参与推动

### 14.2 MVP 的三个核心目标

1. **自迭代闭环运转** — 观察→反思→发现→讨论→改进→验证，全链路跑通
2. **高质量迭代** — 不是随意修改，而是数据驱动、多视角审议、效果验证
3. **交互闭环** — 移动端可随时交互（Telegram），Architect 可主动沟通

### 14.3 MVP 不追求的

- ❌ 在细节打磨上花太多时间（Dashboard 美观度、消息格式完美度）
- ❌ 功能丰富（支持各种任务类型、各种工具）
- ❌ 把系统搞得臃肿复杂

### 14.4 关于复杂度的判断

有 AI 协助开发，**确定性的、可定义可衡量的技术不算复杂**。以下看似复杂但实际可快速实现：
- 信号检测（明确的规则匹配）
- 回滚机制（文件备份和恢复）
- 审批流程（Telegram 消息交互）
- 多视角审议（不同 prompt 的 LLM 调用）

真正的复杂在于「不确定性」和「需要反复调优的细节」，这些才是 MVP 要避免的。

---

## 15. MVP 范围

### 15.1 MVP 包含（✅）

#### 自迭代体系（核心）

| 组件 | 说明 | 为什么必须有 |
|------|------|-------------|
| **规则解释器 + 初始规则集** | ~10 个规则文件 | 没有规则就无法进化 |
| **反思引擎** | 每次任务后轻量反思 | 没有反思就没有学习素材 |
| **信号系统** | 从执行轨迹提取信号 | 没有信号就不知道往哪改 |
| **Observer** | 轻量+深度双模式 | 没有观察就没有客观数据 |
| **Architect** | 分析+设计+执行+验证 | 没有它就不能自主改进 |
| **Multi-Agent Council** | 重要提案经过审议 | 没有审议就容易犯错 |
| **爆炸半径 + 回滚** | 限制范围+自动恢复 | 没有安全网就不敢让它自主改 |
| **审批机制** | 四级分级 | 人类必须有最终控制权 |

#### 迭代所需的上下文记忆

| 组件 | 说明 | 为什么必须有 |
|------|------|-------------|
| **上下文引擎** | token 预算管理+规则注入+记忆注入 | 每次推理的质量基础 |
| **记忆系统** | MEMORY.md+对话记录+每日摘要 | 没有记忆就无法积累经验 |
| **Big Picture** | 系统全局蓝图文档 | Architect 需要参照物 |

#### 交互闭环

| 组件 | 说明 | 为什么必须有 |
|------|------|-------------|
| **Telegram 通道** | 日常对话+Architect 主动沟通 | 移动端交互闭环 |
| **主动沟通** | Architect 发送提案、报告 | 自主触发的关键载体 |

#### 自主触发

| 组件 | 说明 | 为什么必须有 |
|------|------|-------------|
| **信号驱动触发** | 信号累积到阈值唤醒 Architect | 不依赖人主动 |
| **定时触发** | 每日至少运行一次深度分析 | 保底节奏 |
| **NanoBot Heartbeat/Cron** | 定时任务基础设施 | 自主触发的底层支撑 |

#### 关键假设验证

| 假设 | 验证方式 |
|------|---------|
| 规则修改能真正改变系统行为 | 修改规则→观察行为变化 |
| Observer 能发现有价值的模式 | 人工评估 20 条观察笔记 |
| Architect 能设计可执行的方案 | 评估生成提案的质量 |
| 多视角审议能提高方案质量 | 对比有/无审议的提案质量 |
| 自动回滚在指标恶化时生效 | 故意引入坏规则测试 |
| 系统能在同类任务上持续进步 | 连续 5 次同类任务对比 |

### 15.2 MVP 不包含（❌ 留给后续迭代）

| 组件 | 为什么不放 MVP | 何时引入 |
|------|--------------|---------|
| Web Dashboard | 相对独立，可单独验证 | MVP 跑稳后 |
| 向量搜索记忆 | 关键词搜索先够用 | Architect 发现检索不足时 |
| 难度路由器 | 单 Agent 先验证基础能力 | Architect 发现效率问题时 |
| CODER Agent | 独立功能，可后续加 | 需要代码执行能力时 |
| 好奇心引擎完整版 | 基础信号系统先够用 | 系统稳定后探索 |
| A/B 测试框架 | 验证期机制已够用 | 需要更精确对照时 |
| 多通道支持 | Telegram 先够用 | 有需求时 |
| Dashboard 美化 | 不在细节打磨 | 使用中逐步改善 |

### 15.3 MVP 成功标准

| # | 标准 | 度量方式 |
|---|------|---------|
| 1 | **闭环完整性** | 连续 5 个同类任务，第 5 次明显优于第 1 次 |
| 2 | **Observer 有效性** | 20 条观察笔记中 >50% 包含可操作洞察 |
| 3 | **Architect 可用性** | 提案包含问题+方案+预期效果+影响评估 |
| 4 | **审议质量** | 经审议的提案比未审议的方案更稳健 |
| 5 | **主动沟通能力** | 一周内收到的主动消息中，有用占比 >70% |
| 6 | **规则活性** | 两周内至少有规则被验证或建议修改 |
| 7 | **回滚可靠性** | 故意引入坏规则，自动回滚生效 |
| 8 | **交互闭环** | 可通过 Telegram 完成完整的对话+审批流程 |

---

## 16. MVP 实施路线

### Phase 0: 环境搭建（1-2 天）

**目标**：NanoBot 跑起来，Telegram 可对话

- 安装 NanoBot + 配置 API Key
- 创建 Telegram Bot 并连接
- 通读 NanoBot 源码，标记扩展点
- **交付**：可运行的 NanoBot 实例

### Phase 1: 规则系统 + 上下文引擎（3-5 天）

**目标**：系统行为由规则文件驱动

- 创建规则目录结构 + 编写初始规则集（10 个文件）
- 实现 RuleInterpreter（读取→解析→注入）
- 覆写 ContextBuilder（规则+记忆注入+token 预算管理）
- **验证**：修改规则后系统行为改变
- **交付**：规则解释器 + 增强 ContextBuilder

### Phase 2: 记忆系统 + 反思引擎（3-5 天）

**目标**：系统记住经验，任务后自动反思

- 扩展 MemoryStore（对话记录+MEMORY.md+每日摘要）
- 实现反思引擎（轻量反思 Gemini）
- 记忆注入上下文（每次推理前检索相关条目）
- **验证**：第二次同类任务时上下文包含第一次教训
- **交付**：记忆系统 + 反思引擎

### Phase 3: 信号系统 + Observer（3-5 天）

**目标**：Observer 持续运行，提取有价值信号

- 实现信号检测器 + 信号存储
- 实现 Observer（轻量+深度双模式）
- 实现 Observer 调度器
- **验证**：连续使用 3 天，Observer 产出可操作发现
- **交付**：信号系统 + Observer 引擎

### Phase 4: Architect + 审议会 + 回滚（4-6 天）

**目标**：Architect 能基于数据提出经过审议的改进方案

- 实现 Architect 引擎（读取观察→分析→生成提案）
- 实现 Multi-Agent Council（多视角审议）
- 实现审批流程（Telegram 提案发送+回复解析）
- 实现修改执行器 + 回滚管理器
- **验证**：Architect 生成有价值提案、审议提高方案质量、回滚机制可靠
- **交付**：Architect + 审议会 + 回滚系统

### Phase 5: 集成验证（2-3 天）

**目标**：全链路跑通，验证 MVP 成功标准

- 端到端集成测试
- 连续运行 3-5 天
- 验证 8 个成功标准
- **交付**：通过 MVP 成功标准的可运行系统

**总计：12-21 天（约 2-4 周）**

---

## 17. MVP 后的进化路线

MVP 完成后，由 Architect 根据运行数据自主提出迭代方向。以下是预期的进化路线图（但实际方向由数据驱动）：

### 第一阶段：规则调优期（1-4 周）

- 观察初始规则效果，调优和补充
- 学习 Michael 偏好，更新用户模型
- 从 cautious → balanced 策略
- 预期：规则 10 → 15 个，经验规则积累 20+ 条验证策略

### 第二阶段：能力扩展期（4-8 周）

- 基于数据提出扩展提案（示例方向）：
  - 「引入向量搜索记忆——关键词搜索 12 次失败」
  - 「引入难度路由——简单问题浪费 40% token」
  - 「增加 Web Dashboard——远程查看系统状态」
- 预期：2-3 个重要能力升级

### 第三阶段：自主进化期（8-16 周）

- Architect 判断力成熟，获得更多自主权限
- 可能提出的方向：
  - 多 Agent 协作
  - 好奇心引擎完整版
  - CODER Agent + 代码→技能
- 预期：系统从「能用助手」→「真正有用同事」

### 第四阶段：专精深化期（16+ 周）

- 领域专精方案
- 跨系统经验共享（文化基因）
- 架构层面调整

---

## 附录 A：与 V3.1 的主要变更

| 项目 | V3.1 | V3.2 |
|------|------|------|
| 文档定位 | 设计+MVP 混在一起 | 完整设计和 MVP 明确分离 |
| 设计要素 | 未分类 | 标注必要/重要/方案/轮子 |
| 多智能体审议 | 不在 MVP | 放入 MVP（审议会机制） |
| 上下文记忆 | MVP 简化版 | MVP 包含完整记忆体系 |
| 自主触发 | 有设计但 MVP 弱化 | MVP 明确包含信号驱动+定时 |
| 交互闭环 | Telegram 在 MVP | 明确为 MVP 核心目标 |
| 好奇心引擎 | 完全不在 MVP | 完整设计中保留，MVP 通过信号系统覆盖基础功能 |
| Human-as-Executor | 部分覆盖 | 完整设计中保留，MVP 在 Architect 提案中预留字段 |
| 用户模型 | 简化 | 完整设计保留四层模型，MVP 用 user_preferences.md |
| 验证基准 | 6 项 MVP 标准 | 增加组件级量化指标 |
| Web Dashboard | 在 MVP Phase 5 | 移出 MVP，作为独立验证的功能 |
| 文档层次 | 平铺 | 整体框架→工作原理→技术实现→MVP |

## 附录 B：设计要素与历史版本对照

| 要素 | V1 | V2 | V3.1 | V3.2 |
|------|:--:|:--:|:----:|:----:|
| 三层/四层架构 | ✅ | ✅ | ✅ 四层 | ✅ 四层 |
| 上下文引擎 | ✅ 详细 | ✅ | ✅ 简化 | ✅ 恢复详细 |
| 四类记忆 | ✅ 详细 | ✅ | ⚠️ 简化 | ✅ 恢复 |
| 反思引擎 | ✅ 五维 | ✅ | ✅ 轻量+深度 | ✅ 合并 |
| 进化引擎 | ✅ 三机制 | ✅ | ✅ Architect | ✅ Architect+审议 |
| 好奇心引擎 | ✅ | ✅ 意图池 | ❌ | ✅ 设计中保留 |
| 用户模型 | ✅ 四层 | ✅ | ⚠️ 简化 | ✅ 设计中保留 |
| CODER Agent | ❌ | ✅ | ❌ | 🔵 方案 |
| 难度路由 | ❌ | ✅ | ❌ | 🔵 方案 |
| Human-as-Executor | ❌ | ✅ | ⚠️ 部分 | ✅ 设计中保留 |
| 信号系统 | ❌ | ❌ | ✅ | ✅ |
| Observer/Architect | ❌ | ❌ | ✅ | ✅ |
| 爆炸半径控制 | ❌ | ❌ | ✅ | ✅ |
| 多智能体审议 | ❌ | ✅ S&S | ❌ | ✅ Council |
| 验证基准体系 | ❌ | ✅ 8项 | ⚠️ 6项 | ✅ 10项 |

---

> **设计理念总结**：这不是一个需要「开发完成」的产品，而是一个需要「生长起来」的系统。完整设计提供了生长的方向和边界，MVP 提供了生长的起点和最小闭环。系统的每一步复杂化，都应该由运行数据驱动、由 Architect 提案、经审议会讨论、由人类确认——而非预先设计。
